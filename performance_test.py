#!/usr/bin/env python3
"""
æ€§èƒ½æµ‹è¯•è„šæœ¬ - éªŒè¯ä¼˜åŒ–æ•ˆæœ
"""

import time
import psutil
import os
import pandas as pd
import numpy as np
from datetime import datetime

def get_memory_usage():
    """è·å–å½“å‰å†…å­˜ä½¿ç”¨é‡(MB)"""
    process = psutil.Process(os.getpid())
    return process.memory_info().rss / 1024 / 1024

def test_data_loading_performance():
    """æµ‹è¯•æ•°æ®åŠ è½½æ€§èƒ½"""
    print("ğŸ”„ æµ‹è¯•æ•°æ®åŠ è½½æ€§èƒ½...")
    
    files_to_test = [
        'x/train_vis.parquet',
        'x/label_df.parquet', 
        'x/item_attr.parquet'
    ]
    
    results = []
    
    for file_path in files_to_test:
        if os.path.exists(file_path):
            start_time = time.time()
            start_memory = get_memory_usage()
            
            try:
                df = pd.read_parquet(file_path)
                end_time = time.time()
                end_memory = get_memory_usage()
                
                load_time = end_time - start_time
                memory_used = end_memory - start_memory
                
                results.append({
                    'file': os.path.basename(file_path),
                    'size_mb': os.path.getsize(file_path) / 1024 / 1024,
                    'rows': len(df),
                    'cols': len(df.columns),
                    'load_time': load_time,
                    'memory_mb': memory_used,
                    'load_speed_mb_s': (os.path.getsize(file_path) / 1024 / 1024) / load_time
                })
                
                print(f"  âœ… {file_path}: {load_time:.2f}s, {memory_used:.1f}MB")
                
            except Exception as e:
                print(f"  âŒ {file_path}: åŠ è½½å¤±è´¥ - {e}")
        else:
            print(f"  âš ï¸  {file_path}: æ–‡ä»¶ä¸å­˜åœ¨")
    
    return results

def test_memory_optimization():
    """æµ‹è¯•å†…å­˜ä¼˜åŒ–æ•ˆæœ"""
    print("\nğŸ”„ æµ‹è¯•å†…å­˜ä¼˜åŒ–æ•ˆæœ...")
    
    if not os.path.exists('x/train_vis.parquet'):
        print("  âš ï¸  æµ‹è¯•æ•°æ®ä¸å­˜åœ¨ï¼Œè·³è¿‡å†…å­˜ä¼˜åŒ–æµ‹è¯•")
        return None
    
    # æµ‹è¯•åŸå§‹æ•°æ®ç±»å‹ vs ä¼˜åŒ–æ•°æ®ç±»å‹
    df = pd.read_parquet('x/train_vis.parquet')
    
    # åŸå§‹å†…å­˜ä½¿ç”¨
    original_memory = df.memory_usage(deep=True).sum() / 1024 / 1024
    
    # ä¼˜åŒ–æ•°æ®ç±»å‹
    df_optimized = df.copy()
    int_columns = ['buyer_admin_id', 'item_id', 'irank']
    
    for col in int_columns:
        if col in df_optimized.columns:
            df_optimized[col] = pd.to_numeric(df_optimized[col], downcast='integer')
    
    # ä¼˜åŒ–åå†…å­˜ä½¿ç”¨
    optimized_memory = df_optimized.memory_usage(deep=True).sum() / 1024 / 1024
    
    reduction = (original_memory - optimized_memory) / original_memory * 100
    
    print(f"  ğŸ“Š åŸå§‹å†…å­˜ä½¿ç”¨: {original_memory:.1f} MB")
    print(f"  ğŸ“Š ä¼˜åŒ–åå†…å­˜ä½¿ç”¨: {optimized_memory:.1f} MB")
    print(f"  ğŸ“ˆ å†…å­˜å‡å°‘: {reduction:.1f}%")
    
    return {
        'original_memory_mb': original_memory,
        'optimized_memory_mb': optimized_memory,
        'reduction_percent': reduction
    }

def test_vectorization_performance():
    """æµ‹è¯•å‘é‡åŒ–æ“ä½œæ€§èƒ½"""
    print("\nğŸ”„ æµ‹è¯•å‘é‡åŒ–æ“ä½œæ€§èƒ½...")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    n_users = 10000
    n_items = 50000
    n_interactions = 100000
    
    print(f"  ğŸ“Š ç”Ÿæˆæµ‹è¯•æ•°æ®: {n_interactions:,} æ¡äº¤äº’è®°å½•...")
    
    test_data = pd.DataFrame({
        'buyer_admin_id': np.random.randint(1, n_users+1, n_interactions),
        'item_id': np.random.randint(1, n_items+1, n_interactions),
        'score': np.random.random(n_interactions)
    })
    
    # æµ‹è¯•1: ä¼ ç»Ÿgroupby vs å‘é‡åŒ–æ“ä½œ
    print("  ğŸ”„ æµ‹è¯• groupby æ€§èƒ½...")
    
    # ä¼ ç»Ÿæ–¹æ³•
    start_time = time.time()
    traditional_result = test_data.groupby('buyer_admin_id')['score'].mean()
    traditional_time = time.time() - start_time
    
    # å‘é‡åŒ–æ–¹æ³• (ä½¿ç”¨æ›´é«˜æ•ˆçš„èšåˆ)
    start_time = time.time()
    vectorized_result = test_data.groupby('buyer_admin_id', sort=False)['score'].mean()
    vectorized_time = time.time() - start_time
    
    speedup = traditional_time / vectorized_time if vectorized_time > 0 else 1
    
    print(f"  ğŸ“ˆ ä¼ ç»Ÿæ–¹æ³•: {traditional_time:.3f}s")
    print(f"  ğŸ“ˆ å‘é‡åŒ–æ–¹æ³•: {vectorized_time:.3f}s")
    print(f"  ğŸš€ åŠ é€Ÿæ¯”: {speedup:.2f}x")
    
    return {
        'traditional_time': traditional_time,
        'vectorized_time': vectorized_time,
        'speedup': speedup
    }

def generate_performance_report():
    """ç”Ÿæˆæ€§èƒ½æµ‹è¯•æŠ¥å‘Š"""
    print("ğŸ“Š ç”Ÿæˆæ€§èƒ½æµ‹è¯•æŠ¥å‘Š...")
    
    report = {
        'test_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'system_info': {
            'cpu_count': psutil.cpu_count(),
            'memory_total_gb': psutil.virtual_memory().total / 1024 / 1024 / 1024,
            'python_version': f"{psutil.sys.version_info.major}.{psutil.sys.version_info.minor}"
        }
    }
    
    # è¿è¡Œå„é¡¹æµ‹è¯•
    report['data_loading'] = test_data_loading_performance()
    report['memory_optimization'] = test_memory_optimization()
    report['vectorization'] = test_vectorization_performance()
    
    return report

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ æ¨èç³»ç»Ÿæ€§èƒ½æµ‹è¯•")
    print("=" * 50)
    print(f"â° æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ’» ç³»ç»Ÿä¿¡æ¯: CPU {psutil.cpu_count()}æ ¸, å†…å­˜ {psutil.virtual_memory().total/1024/1024/1024:.1f}GB")
    print()
    
    # è¿è¡Œæ€§èƒ½æµ‹è¯•
    report = generate_performance_report()
    
    print("\n" + "=" * 50)
    print("ğŸ“‹ æ€§èƒ½æµ‹è¯•æ€»ç»“:")
    
    # æ•°æ®åŠ è½½æ€§èƒ½
    if report['data_loading']:
        total_load_time = sum(item['load_time'] for item in report['data_loading'])
        avg_speed = np.mean([item['load_speed_mb_s'] for item in report['data_loading']])
        print(f"  ğŸ“– æ•°æ®åŠ è½½: æ€»è€—æ—¶ {total_load_time:.2f}s, å¹³å‡é€Ÿåº¦ {avg_speed:.1f}MB/s")
    
    # å†…å­˜ä¼˜åŒ–
    if report['memory_optimization']:
        reduction = report['memory_optimization']['reduction_percent']
        print(f"  ğŸ’¾ å†…å­˜ä¼˜åŒ–: å‡å°‘ {reduction:.1f}% å†…å­˜ä½¿ç”¨")
    
    # å‘é‡åŒ–åŠ é€Ÿ
    if report['vectorization']:
        speedup = report['vectorization']['speedup']
        print(f"  âš¡ å‘é‡åŒ–åŠ é€Ÿ: {speedup:.2f}x æ€§èƒ½æå‡")
    
    print("\nâœ… æ€§èƒ½æµ‹è¯•å®Œæˆ!")
    
    # ä¿å­˜æŠ¥å‘Š
    import json
    with open('performance_test_report.json', 'w') as f:
        json.dump(report, f, indent=2, default=str)
    print("ğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ° performance_test_report.json")

if __name__ == "__main__":
    main()

