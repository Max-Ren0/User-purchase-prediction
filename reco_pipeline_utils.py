#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨èç³»ç»Ÿç®¡é“å·¥å…·å‡½æ•°
æä¾›é€šç”¨çš„æ•°æ®å¤„ç†å’Œè¯„ä¼°åŠŸèƒ½

ä¸»è¦åŠŸèƒ½ï¼š
- æ•°æ®åŠ è½½å’Œé¢„å¤„ç†
- æ€§èƒ½è¯„ä¼°æŒ‡æ ‡
- ç»“æœä¿å­˜å’Œå¯è§†åŒ–
"""

import os
import pandas as pd
import numpy as np
import time
from datetime import datetime
import json
import warnings
warnings.filterwarnings('ignore')

def load_data(data_dir='data'):
    """åŠ è½½æ‰€æœ‰æ•°æ®æ–‡ä»¶"""
    print("ğŸ“– åŠ è½½æ•°æ®æ–‡ä»¶...")
    
    data = {}
    files = {
        'train_sorted': 'train_sorted.parquet',
        'train_vis': 'train_vis.parquet', 
        'item_attr': 'item_attr.parquet',
        'test_sorted': 'test_sorted.parquet',
        'label_df': 'label_df.parquet'
    }
    
    for key, filename in files.items():
        filepath = os.path.join(data_dir, filename)
        if os.path.exists(filepath):
            data[key] = pd.read_parquet(filepath)
            print(f"  âœ… {key}: {data[key].shape}")
        else:
            print(f"  âŒ ç¼ºå°‘æ–‡ä»¶: {filename}")
            return None
    
    return data

def calculate_metrics(candidates_df, label_df, k=50):
    """è®¡ç®—è¯„ä¼°æŒ‡æ ‡"""
    if len(candidates_df) == 0 or len(label_df) == 0:
        return {'hr': 0.0, 'mrr': 0.0, 'ndcg': 0.0}
    
    # é¢„å¤„ç†æ ‡ç­¾
    label_map = {}
    for _, row in label_df.iterrows():
        label_map[row['buyer_admin_id']] = row['label_item']
    
    hr_hits = 0
    mrr_sum = 0.0
    ndcg_sum = 0.0
    total_users = len(label_map)
    
    for user_id, group in candidates_df.groupby('buyer_admin_id'):
        if user_id in label_map:
            user_items = group['item_id'].values[:k]  # å–å‰kä¸ª
            target_item = label_map[user_id]
            
            if target_item in user_items:
                hr_hits += 1
                rank = np.where(user_items == target_item)[0][0] + 1
                mrr_sum += 1.0 / rank
                ndcg_sum += 1.0 / np.log2(rank + 1)
    
    hr = hr_hits / total_users if total_users > 0 else 0.0
    mrr = mrr_sum / total_users if total_users > 0 else 0.0
    ndcg = ndcg_sum / total_users if total_users > 0 else 0.0
    
    return {
        'hr': hr,
        'mrr': mrr,
        'ndcg': ndcg,
        'total_users': total_users,
        'hits': hr_hits
    }

def save_results(results, filename, data_dir='results'):
    """ä¿å­˜ç»“æœ"""
    os.makedirs(data_dir, exist_ok=True)
    
    if isinstance(results, pd.DataFrame):
        filepath = os.path.join(data_dir, filename)
        results.to_parquet(filepath, index=False, compression='snappy')
        print(f"âœ… ä¿å­˜ç»“æœ: {filepath}")
    else:
        filepath = os.path.join(data_dir, filename)
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        print(f"âœ… ä¿å­˜ç»“æœ: {filepath}")

def load_config(config_file='competition_config.json'):
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    if os.path.exists(config_file):
        with open(config_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    else:
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
        return None

def get_optimized_params(config_file='competition_config.json', mode='production'):
    """è·å–ä¼˜åŒ–åçš„å‚æ•°"""
    config = load_config(config_file)
    if config and 'params' in config:
        return config['params'].get(mode, {})
    else:
        print("âŒ æ— æ³•åŠ è½½ä¼˜åŒ–å‚æ•°ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°")
        return {
            'covisit_window': 4,
            'covisit_top_per_a': 317,
            'recent_k': 4,
            'cand_per_recent': 69,
            'tau_days': 11,
            'per_cate_pool': 38,
            'per_store_pool': 96,
            'pop_pool': 4863,
            'recall_cap': 866,
            'batch_size': 4000
        }

def print_performance_summary(metrics, title="æ€§èƒ½è¯„ä¼°"):
    """æ‰“å°æ€§èƒ½æ‘˜è¦"""
    print(f"\nğŸ“Š {title}")
    print("=" * 40)
    print(f"HR@50:   {metrics.get('hr', 0):.4f}")
    print(f"MRR@50:  {metrics.get('mrr', 0):.4f}")
    print(f"NDCG@50: {metrics.get('ndcg', 0):.4f}")
    
    if 'total_users' in metrics:
        print(f"æ€»ç”¨æˆ·æ•°: {metrics['total_users']:,}")
    if 'hits' in metrics:
        print(f"å‘½ä¸­æ•°: {metrics['hits']:,}")

def check_data_quality(data):
    """æ£€æŸ¥æ•°æ®è´¨é‡"""
    print("\nğŸ” æ•°æ®è´¨é‡æ£€æŸ¥")
    print("=" * 30)
    
    for name, df in data.items():
        print(f"\nğŸ“Š {name}:")
        print(f"  å½¢çŠ¶: {df.shape}")
        print(f"  å†…å­˜: {df.memory_usage(deep=True).sum() / 1024 / 1024:.1f}MB")
        print(f"  ç¼ºå¤±å€¼: {df.isnull().sum().sum()}")
        
        if 'buyer_admin_id' in df.columns:
            print(f"  ç”¨æˆ·æ•°: {df['buyer_admin_id'].nunique():,}")
        if 'item_id' in df.columns:
            print(f"  å•†å“æ•°: {df['item_id'].nunique():,}")

def create_submission(candidates_df, output_file='submission.csv'):
    """åˆ›å»ºæäº¤æ–‡ä»¶"""
    if len(candidates_df) == 0:
        print("âŒ å€™é€‰æ•°æ®ä¸ºç©ºï¼Œæ— æ³•åˆ›å»ºæäº¤æ–‡ä»¶")
        return
    
    # æŒ‰ç”¨æˆ·åˆ†ç»„ï¼Œå–å‰50ä¸ªå€™é€‰
    submission = []
    for user_id, group in candidates_df.groupby('buyer_admin_id'):
        user_items = group['item_id'].values[:50]  # å–å‰50ä¸ª
        submission.append({
            'buyer_admin_id': user_id,
            'item_id': ' '.join(map(str, user_items))
        })
    
    submission_df = pd.DataFrame(submission)
    submission_df.to_csv(output_file, index=False)
    print(f"âœ… æäº¤æ–‡ä»¶å·²åˆ›å»º: {output_file}")
    print(f"ğŸ“Š æäº¤ç”¨æˆ·æ•°: {len(submission_df):,}")

def benchmark_performance(func, *args, **kwargs):
    """æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    start_time = time.time()
    result = func(*args, **kwargs)
    end_time = time.time()
    
    print(f"â±ï¸  æ‰§è¡Œæ—¶é—´: {end_time - start_time:.2f}ç§’")
    return result

def memory_usage():
    """å†…å­˜ä½¿ç”¨æƒ…å†µ"""
    import psutil
    process = psutil.Process()
    memory_info = process.memory_info()
    print(f"ğŸ’¾ å†…å­˜ä½¿ç”¨: {memory_info.rss / 1024 / 1024:.1f}MB")

def setup_logging(log_file='pipeline.log'):
    """è®¾ç½®æ—¥å¿—"""
    import logging
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    
    return logging.getLogger(__name__)

def validate_pipeline():
    """éªŒè¯ç®¡é“å®Œæ•´æ€§"""
    print("ğŸ” éªŒè¯ç®¡é“å®Œæ•´æ€§...")
    
    # æ£€æŸ¥å¿…è¦æ–‡ä»¶
    required_files = [
        'data/Antai_hackathon_train.csv',
        'data/Antai_hackathon_attr.csv',
        'data/dianshang_test.csv',
        'competition_config.json'
    ]
    
    missing_files = []
    for file in required_files:
        if not os.path.exists(file):
            missing_files.append(file)
    
    if missing_files:
        print("âŒ ç¼ºå°‘å¿…è¦æ–‡ä»¶:")
        for file in missing_files:
            print(f"  - {file}")
        return False
    
    # æ£€æŸ¥Pythonä¾èµ–
    required_packages = [
        'pandas', 'numpy', 'sklearn', 'skopt', 'lightgbm'
    ]
    
    missing_packages = []
    for package in required_packages:
        try:
            __import__(package)
        except ImportError:
            missing_packages.append(package)
    
    if missing_packages:
        print("âŒ ç¼ºå°‘PythonåŒ…:")
        for package in missing_packages:
            print(f"  - {package}")
        return False
    
    print("âœ… ç®¡é“éªŒè¯é€šè¿‡")
    return True

if __name__ == "__main__":
    print("ğŸ”§ æ¨èç³»ç»Ÿç®¡é“å·¥å…·")
    print("=" * 30)
    
    # éªŒè¯ç®¡é“
    if validate_pipeline():
        print("âœ… ç³»ç»Ÿå°±ç»ª")
    else:
        print("âŒ ç³»ç»Ÿé…ç½®ä¸å®Œæ•´")
