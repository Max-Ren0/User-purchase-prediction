{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c947909b",
   "metadata": {},
   "source": [
    "# ğŸ¯ æ’åºæ¨¡å‹è®­ç»ƒä¸è¯„ä¼°æ¨¡å— (2_rank.ipynb)\n",
    "\n",
    "## ğŸ“‹ æ¨¡å—åŠŸèƒ½\n",
    "å®ç°**Learning to Rank**æ’åºæ¨¡å‹ï¼Œå°†å¬å›çš„å€™é€‰å•†å“è¿›è¡Œç²¾å‡†æ’åºï¼Œæå‡æ¨èè´¨é‡ã€‚\n",
    "\n",
    "## ğŸš€ æ ¸å¿ƒåŠŸèƒ½\n",
    "1. **ğŸ”§ ç‰¹å¾å·¥ç¨‹**: æ„é€ ç”¨æˆ·-å•†å“äº¤äº’ç‰¹å¾\n",
    "2. **ğŸ¤– æ¨¡å‹è®­ç»ƒ**: LightGBMä¼˜å…ˆï¼ŒRandomForestå¤‡é€‰\n",
    "3. **ğŸ“Š æ¨¡å‹è¯„ä¼°**: Recall@50ã€NDCG@50ç­‰æ ‡å‡†æŒ‡æ ‡\n",
    "4. **ğŸ”¬ æ¶ˆèå®éªŒ**: é‡åŒ–å„ç»„ä»¶çš„è´¡çŒ®åº¦\n",
    "5. **ğŸ’¾ æ¨¡å‹ä¿å­˜**: å®Œæ•´çš„æ¨¡å‹æŒä¹…åŒ–\n",
    "\n",
    "## ğŸ”¬ æ¶ˆèå®éªŒè®¾è®¡\n",
    "- **A1**: ä»…ååŒè¿‡æ»¤ vs å¤šè·¯å¬å›ï¼ˆæ— æ’åºï¼‰\n",
    "- **A2**: å¤šè·¯å¬å›æ— æ’åº vs å¤šè·¯å¬å›+æ’åºæ¨¡å‹\n",
    "\n",
    "## ğŸ”§ è¾“å‡ºæ–‡ä»¶\n",
    "### è¯„ä¼°ç»“æœ\n",
    "- `metrics_ablation.csv`: æ¶ˆèå®éªŒæŒ‡æ ‡å¯¹æ¯”\n",
    "- `feature_importance.csv`: ç‰¹å¾é‡è¦æ€§åˆ†æ\n",
    "\n",
    "### é¢„æµ‹ç»“æœ\n",
    "- `mm_norank.parquet`: å¤šè·¯å¬å›æ— æ’åºé¢„æµ‹\n",
    "- `mm_rank.parquet`: å¤šè·¯å¬å›+æ’åºé¢„æµ‹  \n",
    "- `cm_norank.parquet`: ååŒè¿‡æ»¤æ— æ’åºé¢„æµ‹\n",
    "\n",
    "### æ¨¡å‹æ–‡ä»¶\n",
    "- `model_lgb.pkl`: è®­ç»ƒå¥½çš„æ’åºæ¨¡å‹ï¼ˆä¾›çº¿ä¸Šä½¿ç”¨ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770485b5",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ ç¯å¢ƒé…ç½®ä¸æ•°æ®åŠ è½½\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8f3862",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# ç¯å¢ƒé…ç½®ä¸ä¾èµ–å¯¼å…¥\n",
    "# =============================================================================\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# æœºå™¨å­¦ä¹ ç›¸å…³\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    HAS_LIGHTGBM = True\n",
    "    print(\"âœ… LightGBM å¯ç”¨\")\n",
    "except ImportError:\n",
    "    HAS_LIGHTGBM = False\n",
    "    print(\"âš ï¸  LightGBM ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ RandomForest\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pickle\n",
    "\n",
    "# é…ç½®å‚æ•°\n",
    "OUTDIR = '../x'  # ä¿®æ­£ä¸ºæ­£ç¡®çš„è¾“å‡ºç›®å½•\n",
    "print(f'ğŸ“ è¾“å‡ºç›®å½•: {OUTDIR}')\n",
    "print(f'â° å¼€å§‹æ—¶é—´: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "\n",
    "# æ£€æŸ¥å¿…è¦æ–‡ä»¶\n",
    "required_files = [\n",
    "    'train_vis.parquet',\n",
    "    'label_df.parquet', \n",
    "    'cands_multi.parquet',\n",
    "    'cands_covisit_only.parquet'\n",
    "]\n",
    "\n",
    "print(\"ğŸ” æ£€æŸ¥æ•°æ®æ–‡ä»¶...\")\n",
    "for file in required_files:\n",
    "    if not os.path.exists(f'{OUTDIR}/{file}'):\n",
    "        raise FileNotFoundError(f\"âŒ ç¼ºå°‘æ–‡ä»¶: {file}ï¼Œè¯·å…ˆè¿è¡Œå‰åºnotebook\")\n",
    "    print(f\"  âœ… {file}\")\n",
    "\n",
    "print(\"âœ… ç¯å¢ƒé…ç½®å®Œæˆ\")\n",
    "cands_covisit = pd.read_parquet(f'{OUTDIR}/cands_covisit_only.parquet')\n",
    "\n",
    "# é€šç”¨ç»Ÿè®¡ç‰¹å¾ï¼ˆåŸºäº train_visï¼‰\n",
    "user_cnt = train_vis.groupby('buyer_admin_id').size().rename('user_hist_cnt')\n",
    "item_cnt = train_vis.groupby('item_id').size().rename('item_pop_cnt')\n",
    "\n",
    "def add_common_feats(df):\n",
    "    return (df.merge(user_cnt, on='buyer_admin_id', how='left')\n",
    "              .merge(item_cnt, on='item_id', how='left')).fillna(0)\n",
    "\n",
    "def add_label(df):\n",
    "    d = df.merge(label_df, on='buyer_admin_id', how='left')\n",
    "    d['label'] = (d['item_id']==d['label_item']).astype(int)\n",
    "    return d.drop(columns=['label_item'])\n",
    "\n",
    "def recall_at_k(df, k=50):\n",
    "    ok, tot = 0, df['buyer_admin_id'].nunique()\n",
    "    for uid, g in df.groupby('buyer_admin_id'):\n",
    "        ok += g.sort_values('pred', ascending=False).head(k)['label'].max()\n",
    "    return ok / max(tot,1)\n",
    "\n",
    "def ndcg_at_k(df, k=50):\n",
    "    s, tot = 0.0, df['buyer_admin_id'].nunique()\n",
    "    for _, g in df.groupby('buyer_admin_id'):\n",
    "        rels = g.sort_values('pred', ascending=False).head(k)['label'].tolist()\n",
    "        dcg = sum(rel / math.log2(i+2) for i, rel in enumerate(rels))\n",
    "        s += dcg  # ç•™ä¸€éªŒè¯ idcg = 1\n",
    "    return s / max(tot,1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98192d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# æ•°æ®åŠ è½½\n",
    "# =============================================================================\n",
    "print(\"ğŸ“– æ­£åœ¨åŠ è½½æ•°æ®...\")\n",
    "\n",
    "# åŠ è½½åŸºç¡€æ•°æ®\n",
    "train_vis = pd.read_parquet(f'{OUTDIR}/train_vis.parquet')\n",
    "label_df = pd.read_parquet(f'{OUTDIR}/label_df.parquet')\n",
    "\n",
    "# åŠ è½½å€™é€‰æ•°æ®\n",
    "cands_multi = pd.read_parquet(f'{OUTDIR}/cands_multi.parquet')\n",
    "cands_covisit = pd.read_parquet(f'{OUTDIR}/cands_covisit_only.parquet')\n",
    "\n",
    "print(\"âœ… æ•°æ®åŠ è½½å®Œæˆ\")\n",
    "print(f\"ğŸ“Š æ•°æ®è§„æ¨¡:\")\n",
    "print(f\"  è®­ç»ƒæ•°æ®: {train_vis.shape}\")\n",
    "print(f\"  æ ‡ç­¾æ•°æ®: {label_df.shape}\")\n",
    "print(f\"  å¤šè·¯å€™é€‰: {cands_multi.shape}\")\n",
    "print(f\"  ååŒå€™é€‰: {cands_covisit.shape}\")\n",
    "\n",
    "# æ•°æ®è´¨é‡æ£€æŸ¥\n",
    "print(f\"\\nğŸ” æ•°æ®è´¨é‡æ£€æŸ¥:\")\n",
    "print(f\"  å¤šè·¯å€™é€‰ç”¨æˆ·æ•°: {cands_multi['buyer_admin_id'].nunique():,}\")\n",
    "print(f\"  ååŒå€™é€‰ç”¨æˆ·æ•°: {cands_covisit['buyer_admin_id'].nunique():,}\")\n",
    "print(f\"  æ ‡ç­¾ç”¨æˆ·æ•°: {label_df['buyer_admin_id'].nunique():,}\")\n",
    "\n",
    "# æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§\n",
    "multi_users = set(cands_multi['buyer_admin_id'].unique())\n",
    "label_users = set(label_df['buyer_admin_id'].unique())\n",
    "overlap = len(multi_users & label_users)\n",
    "print(f\"  ç”¨æˆ·é‡å åº¦: {overlap:,}/{len(label_users):,} ({overlap/len(label_users):.1%})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b8c220",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ è¯„ä¼°å‡½æ•°å®šä¹‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0c1c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# æ¨èç³»ç»Ÿè¯„ä¼°å‡½æ•°\n",
    "# =============================================================================\n",
    "def recall_at_k(y_true, y_pred, k=50):\n",
    "    \"\"\"\n",
    "    è®¡ç®— Recall@K\n",
    "    \n",
    "    Args:\n",
    "        y_true: çœŸå®æ ‡ç­¾ (user_id -> item_id)\n",
    "        y_pred: é¢„æµ‹ç»“æœ (user_id -> [item_ids])\n",
    "        k: Top-K\n",
    "        \n",
    "    Returns:\n",
    "        float: Recall@K å€¼\n",
    "    \"\"\"\n",
    "    if len(y_true) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    hits = 0\n",
    "    total = len(y_true)\n",
    "    \n",
    "    for user_id, true_item in y_true.items():\n",
    "        if user_id in y_pred:\n",
    "            pred_items = y_pred[user_id][:k]\n",
    "            if true_item in pred_items:\n",
    "                hits += 1\n",
    "    \n",
    "    return hits / total\n",
    "\n",
    "def ndcg_at_k(y_true, y_pred, k=50):\n",
    "    \"\"\"\n",
    "    è®¡ç®— NDCG@K\n",
    "    \n",
    "    Args:\n",
    "        y_true: çœŸå®æ ‡ç­¾ (user_id -> item_id)\n",
    "        y_pred: é¢„æµ‹ç»“æœ (user_id -> [item_ids])\n",
    "        k: Top-K\n",
    "        \n",
    "    Returns:\n",
    "        float: NDCG@K å€¼\n",
    "    \"\"\"\n",
    "    if len(y_true) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    ndcg_sum = 0.0\n",
    "    total = len(y_true)\n",
    "    \n",
    "    for user_id, true_item in y_true.items():\n",
    "        if user_id in y_pred:\n",
    "            pred_items = y_pred[user_id][:k]\n",
    "            \n",
    "            # è®¡ç®—DCG\n",
    "            dcg = 0.0\n",
    "            for i, item in enumerate(pred_items):\n",
    "                if item == true_item:\n",
    "                    dcg = 1.0 / math.log2(i + 2)  # i+2 because log2(1)=0\n",
    "                    break\n",
    "            \n",
    "            # è®¡ç®—IDCG (ç†æƒ³æƒ…å†µä¸‹ä¸º1.0)\n",
    "            idcg = 1.0  # å› ä¸ºåªæœ‰ä¸€ä¸ªç›¸å…³ç‰©å“\n",
    "            \n",
    "            # è®¡ç®—NDCG\n",
    "            if idcg > 0:\n",
    "                ndcg_sum += dcg / idcg\n",
    "    \n",
    "    return ndcg_sum / total\n",
    "\n",
    "def evaluate_predictions(cands_df, label_df, score_col='pre_score', k=50):\n",
    "    \"\"\"\n",
    "    è¯„ä¼°é¢„æµ‹ç»“æœ\n",
    "    \n",
    "    Args:\n",
    "        cands_df: å€™é€‰DataFrameï¼ŒåŒ…å« buyer_admin_id, item_id, score_col\n",
    "        label_df: æ ‡ç­¾DataFrameï¼ŒåŒ…å« buyer_admin_id, label_item\n",
    "        score_col: è¯„åˆ†åˆ—å\n",
    "        k: Top-K\n",
    "        \n",
    "    Returns:\n",
    "        dict: è¯„ä¼°æŒ‡æ ‡\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ“Š è¯„ä¼°é¢„æµ‹ç»“æœ (K={k}, score_col={score_col})...\")\n",
    "    \n",
    "    # æ„å»ºçœŸå®æ ‡ç­¾å­—å…¸\n",
    "    y_true = dict(zip(label_df['buyer_admin_id'], label_df['label_item']))\n",
    "    \n",
    "    # æ„å»ºé¢„æµ‹ç»“æœå­—å…¸\n",
    "    y_pred = {}\n",
    "    cands_sorted = cands_df.sort_values(['buyer_admin_id', score_col], ascending=[True, False])\n",
    "    \n",
    "    for user_id, group in cands_sorted.groupby('buyer_admin_id'):\n",
    "        y_pred[user_id] = group['item_id'].tolist()\n",
    "    \n",
    "    # è®¡ç®—æŒ‡æ ‡\n",
    "    recall = recall_at_k(y_true, y_pred, k)\n",
    "    ndcg = ndcg_at_k(y_true, y_pred, k)\n",
    "    \n",
    "    # è¦†ç›–ç‡ç»Ÿè®¡\n",
    "    pred_users = set(y_pred.keys())\n",
    "    true_users = set(y_true.keys())\n",
    "    coverage = len(pred_users & true_users) / len(true_users)\n",
    "    \n",
    "    metrics = {\n",
    "        f'recall@{k}': recall,\n",
    "        f'ndcg@{k}': ndcg,\n",
    "        'coverage': coverage,\n",
    "        'total_users': len(true_users),\n",
    "        'pred_users': len(pred_users)\n",
    "    }\n",
    "    \n",
    "    print(f\"  ğŸ“ˆ Recall@{k}: {recall:.4f}\")\n",
    "    print(f\"  ğŸ“ˆ NDCG@{k}: {ndcg:.4f}\")\n",
    "    print(f\"  ğŸ“Š è¦†ç›–ç‡: {coverage:.4f}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "print(\"âœ… è¯„ä¼°å‡½æ•°å®šä¹‰å®Œæˆ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcf7465",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === å‡†å¤‡æ•°æ® ===\n",
    "cm = add_common_feats(add_label(cands_covisit.copy()))\n",
    "mm = add_common_feats(add_label(cands_multi.copy()))\n",
    "\n",
    "# A1: No-Rank baselinesï¼ˆpred = pre_scoreï¼‰\n",
    "cm_nr = cm.copy(); cm_nr['pred'] = cm_nr['pre_score']\n",
    "mm_nr = mm.copy(); mm_nr['pred'] = mm_nr['pre_score']\n",
    "\n",
    "mA1 = {\n",
    "    'covisit_only_NoRank': dict(\n",
    "        recall_at_50 = round(recall_at_k(cm_nr, 50), 6),\n",
    "        ndcg_at_50   = round(ndcg_at_k(cm_nr, 50), 6)\n",
    "    ),\n",
    "    'multi_NoRank': dict(\n",
    "        recall_at_50 = round(recall_at_k(mm_nr, 50), 6),\n",
    "        ndcg_at_50   = round(ndcg_at_k(mm_nr, 50), 6)\n",
    "    )\n",
    "}\n",
    "mA1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68699712",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === A2: Multi + Ranker ===\n",
    "feat_cols = ['score_rebuy','score_covisit','is_cate_hot','is_store_hot','is_global_pop',\n",
    "             'src_count','user_hist_cnt','item_pop_cnt','pre_score']\n",
    "\n",
    "# LightGBM ä¼˜å…ˆï¼Œæ— æ³•ä½¿ç”¨åˆ™é™çº§ RF\n",
    "try:\n",
    "    from lightgbm import LGBMClassifier\n",
    "    has_lgbm = True\n",
    "except Exception:\n",
    "    has_lgbm = False\n",
    "    from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "\n",
    "if has_lgbm:\n",
    "    model = LGBMClassifier(n_estimators=400, learning_rate=0.05,\n",
    "                           num_leaves=63, subsample=0.8, colsample_bytree=0.8,\n",
    "                           random_state=2025)\n",
    "else:\n",
    "    model = RFC(n_estimators=300, random_state=2025, n_jobs=-1)\n",
    "\n",
    "X = mm[feat_cols].values\n",
    "y = mm['label'].values\n",
    "model.fit(X, y)\n",
    "\n",
    "mm_rank = mm.copy()\n",
    "if hasattr(model, 'predict_proba'):\n",
    "    mm_rank['pred'] = model.predict_proba(mm[feat_cols])[:,1]\n",
    "elif hasattr(model, 'decision_function'):\n",
    "    v = model.decision_function(mm[feat_cols])\n",
    "    mm_rank['pred'] = (v - v.min())/(v.max()-v.min()+1e-9)\n",
    "else:\n",
    "    mm_rank['pred'] = model.predict(mm[feat_cols]).astype(float)\n",
    "\n",
    "mA2 = {\n",
    "    'multi_Ranker': dict(\n",
    "        recall_at_50 = round(recall_at_k(mm_rank, 50), 6),\n",
    "        ndcg_at_50   = round(ndcg_at_k(mm_rank, 50), 6)\n",
    "    )\n",
    "}\n",
    "mA2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c922b993",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === ä¿å­˜æŒ‡æ ‡ã€æ˜ç»†ã€æ¨¡å‹ã€ç‰¹å¾é‡è¦æ€§ ===\n",
    "import pandas as pd, numpy as np, os, joblib\n",
    "\n",
    "metrics = pd.DataFrame([\n",
    "    dict(setting='A1_covisit_only_NoRank', **mA1['covisit_only_NoRank']),\n",
    "    dict(setting='A1_multi_NoRank',        **mA1['multi_NoRank']),\n",
    "    dict(setting='A2_multi_Ranker',        **mA2['multi_Ranker']),\n",
    "])\n",
    "metrics.to_csv(f'{OUTDIR}/metrics_ablation.csv', index=False)\n",
    "\n",
    "mm_nr.to_parquet(f'{OUTDIR}/mm_norank.parquet', index=False)\n",
    "mm_rank.to_parquet(f'{OUTDIR}/mm_rank.parquet', index=False)\n",
    "cm_nr.to_parquet(f'{OUTDIR}/cm_norank.parquet', index=False)\n",
    "\n",
    "# ä¿å­˜æ¨¡å‹ï¼ˆç»Ÿä¸€æ–‡ä»¶åï¼Œä¾¿äº 4_online è‡ªåŠ¨åŠ è½½ï¼‰\n",
    "model_path = os.path.join(OUTDIR, 'model_lgb.pkl')\n",
    "joblib.dump(model, model_path)\n",
    "print('Model saved to', model_path)\n",
    "\n",
    "# ç‰¹å¾é‡è¦æ€§ï¼ˆè‹¥å¯ç”¨ï¼‰\n",
    "fi_path = os.path.join(OUTDIR, 'feature_importance.csv')\n",
    "if hasattr(model, 'feature_importances_'):\n",
    "    importances = getattr(model, 'feature_importances_')\n",
    "    pd.DataFrame({'feature': feat_cols, 'importance': importances})       .sort_values('importance', ascending=False).to_csv(fi_path, index=False)\n",
    "    print('Feature importance saved to', fi_path)\n",
    "else:\n",
    "    print('Model has no feature_importances_; skip.')\n",
    "\n",
    "print('\\nMetrics:'); print(metrics)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
