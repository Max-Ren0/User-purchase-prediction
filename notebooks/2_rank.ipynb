{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c947909b",
   "metadata": {},
   "source": [
    "# 🎯 排序模型训练与评估模块 (2_rank.ipynb)\n",
    "\n",
    "## 📋 模块功能\n",
    "实现**Learning to Rank**排序模型，将召回的候选商品进行精准排序，提升推荐质量。\n",
    "\n",
    "## 🚀 核心功能\n",
    "1. **🔧 特征工程**: 构造用户-商品交互特征\n",
    "2. **🤖 模型训练**: LightGBM优先，RandomForest备选\n",
    "3. **📊 模型评估**: Recall@50、NDCG@50等标准指标\n",
    "4. **🔬 消融实验**: 量化各组件的贡献度\n",
    "5. **💾 模型保存**: 完整的模型持久化\n",
    "\n",
    "## 🔬 消融实验设计\n",
    "- **A1**: 仅协同过滤 vs 多路召回（无排序）\n",
    "- **A2**: 多路召回无排序 vs 多路召回+排序模型\n",
    "\n",
    "## 🔧 输出文件\n",
    "### 评估结果\n",
    "- `metrics_ablation.csv`: 消融实验指标对比\n",
    "- `feature_importance.csv`: 特征重要性分析\n",
    "\n",
    "### 预测结果\n",
    "- `mm_norank.parquet`: 多路召回无排序预测\n",
    "- `mm_rank.parquet`: 多路召回+排序预测  \n",
    "- `cm_norank.parquet`: 协同过滤无排序预测\n",
    "\n",
    "### 模型文件\n",
    "- `model_lgb.pkl`: 训练好的排序模型（供线上使用）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770485b5",
   "metadata": {},
   "source": [
    "## 1️⃣ 环境配置与数据加载\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8f3862",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 环境配置与依赖导入\n",
    "# =============================================================================\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 机器学习相关\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    HAS_LIGHTGBM = True\n",
    "    print(\"✅ LightGBM 可用\")\n",
    "except ImportError:\n",
    "    HAS_LIGHTGBM = False\n",
    "    print(\"⚠️  LightGBM 不可用，将使用 RandomForest\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pickle\n",
    "\n",
    "# 配置参数\n",
    "OUTDIR = '../x'  # 修正为正确的输出目录\n",
    "print(f'📁 输出目录: {OUTDIR}')\n",
    "print(f'⏰ 开始时间: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "\n",
    "# 检查必要文件\n",
    "required_files = [\n",
    "    'train_vis.parquet',\n",
    "    'label_df.parquet', \n",
    "    'cands_multi.parquet',\n",
    "    'cands_covisit_only.parquet'\n",
    "]\n",
    "\n",
    "print(\"🔍 检查数据文件...\")\n",
    "for file in required_files:\n",
    "    if not os.path.exists(f'{OUTDIR}/{file}'):\n",
    "        raise FileNotFoundError(f\"❌ 缺少文件: {file}，请先运行前序notebook\")\n",
    "    print(f\"  ✅ {file}\")\n",
    "\n",
    "print(\"✅ 环境配置完成\")\n",
    "cands_covisit = pd.read_parquet(f'{OUTDIR}/cands_covisit_only.parquet')\n",
    "\n",
    "# 通用统计特征（基于 train_vis）\n",
    "user_cnt = train_vis.groupby('buyer_admin_id').size().rename('user_hist_cnt')\n",
    "item_cnt = train_vis.groupby('item_id').size().rename('item_pop_cnt')\n",
    "\n",
    "def add_common_feats(df):\n",
    "    return (df.merge(user_cnt, on='buyer_admin_id', how='left')\n",
    "              .merge(item_cnt, on='item_id', how='left')).fillna(0)\n",
    "\n",
    "def add_label(df):\n",
    "    d = df.merge(label_df, on='buyer_admin_id', how='left')\n",
    "    d['label'] = (d['item_id']==d['label_item']).astype(int)\n",
    "    return d.drop(columns=['label_item'])\n",
    "\n",
    "def recall_at_k(df, k=50):\n",
    "    ok, tot = 0, df['buyer_admin_id'].nunique()\n",
    "    for uid, g in df.groupby('buyer_admin_id'):\n",
    "        ok += g.sort_values('pred', ascending=False).head(k)['label'].max()\n",
    "    return ok / max(tot,1)\n",
    "\n",
    "def ndcg_at_k(df, k=50):\n",
    "    s, tot = 0.0, df['buyer_admin_id'].nunique()\n",
    "    for _, g in df.groupby('buyer_admin_id'):\n",
    "        rels = g.sort_values('pred', ascending=False).head(k)['label'].tolist()\n",
    "        dcg = sum(rel / math.log2(i+2) for i, rel in enumerate(rels))\n",
    "        s += dcg  # 留一验证 idcg = 1\n",
    "    return s / max(tot,1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98192d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 数据加载\n",
    "# =============================================================================\n",
    "print(\"📖 正在加载数据...\")\n",
    "\n",
    "# 加载基础数据\n",
    "train_vis = pd.read_parquet(f'{OUTDIR}/train_vis.parquet')\n",
    "label_df = pd.read_parquet(f'{OUTDIR}/label_df.parquet')\n",
    "\n",
    "# 加载候选数据\n",
    "cands_multi = pd.read_parquet(f'{OUTDIR}/cands_multi.parquet')\n",
    "cands_covisit = pd.read_parquet(f'{OUTDIR}/cands_covisit_only.parquet')\n",
    "\n",
    "print(\"✅ 数据加载完成\")\n",
    "print(f\"📊 数据规模:\")\n",
    "print(f\"  训练数据: {train_vis.shape}\")\n",
    "print(f\"  标签数据: {label_df.shape}\")\n",
    "print(f\"  多路候选: {cands_multi.shape}\")\n",
    "print(f\"  协同候选: {cands_covisit.shape}\")\n",
    "\n",
    "# 数据质量检查\n",
    "print(f\"\\n🔍 数据质量检查:\")\n",
    "print(f\"  多路候选用户数: {cands_multi['buyer_admin_id'].nunique():,}\")\n",
    "print(f\"  协同候选用户数: {cands_covisit['buyer_admin_id'].nunique():,}\")\n",
    "print(f\"  标签用户数: {label_df['buyer_admin_id'].nunique():,}\")\n",
    "\n",
    "# 检查数据一致性\n",
    "multi_users = set(cands_multi['buyer_admin_id'].unique())\n",
    "label_users = set(label_df['buyer_admin_id'].unique())\n",
    "overlap = len(multi_users & label_users)\n",
    "print(f\"  用户重叠度: {overlap:,}/{len(label_users):,} ({overlap/len(label_users):.1%})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b8c220",
   "metadata": {},
   "source": [
    "## 2️⃣ 评估函数定义\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0c1c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 推荐系统评估函数\n",
    "# =============================================================================\n",
    "def recall_at_k(y_true, y_pred, k=50):\n",
    "    \"\"\"\n",
    "    计算 Recall@K\n",
    "    \n",
    "    Args:\n",
    "        y_true: 真实标签 (user_id -> item_id)\n",
    "        y_pred: 预测结果 (user_id -> [item_ids])\n",
    "        k: Top-K\n",
    "        \n",
    "    Returns:\n",
    "        float: Recall@K 值\n",
    "    \"\"\"\n",
    "    if len(y_true) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    hits = 0\n",
    "    total = len(y_true)\n",
    "    \n",
    "    for user_id, true_item in y_true.items():\n",
    "        if user_id in y_pred:\n",
    "            pred_items = y_pred[user_id][:k]\n",
    "            if true_item in pred_items:\n",
    "                hits += 1\n",
    "    \n",
    "    return hits / total\n",
    "\n",
    "def ndcg_at_k(y_true, y_pred, k=50):\n",
    "    \"\"\"\n",
    "    计算 NDCG@K\n",
    "    \n",
    "    Args:\n",
    "        y_true: 真实标签 (user_id -> item_id)\n",
    "        y_pred: 预测结果 (user_id -> [item_ids])\n",
    "        k: Top-K\n",
    "        \n",
    "    Returns:\n",
    "        float: NDCG@K 值\n",
    "    \"\"\"\n",
    "    if len(y_true) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    ndcg_sum = 0.0\n",
    "    total = len(y_true)\n",
    "    \n",
    "    for user_id, true_item in y_true.items():\n",
    "        if user_id in y_pred:\n",
    "            pred_items = y_pred[user_id][:k]\n",
    "            \n",
    "            # 计算DCG\n",
    "            dcg = 0.0\n",
    "            for i, item in enumerate(pred_items):\n",
    "                if item == true_item:\n",
    "                    dcg = 1.0 / math.log2(i + 2)  # i+2 because log2(1)=0\n",
    "                    break\n",
    "            \n",
    "            # 计算IDCG (理想情况下为1.0)\n",
    "            idcg = 1.0  # 因为只有一个相关物品\n",
    "            \n",
    "            # 计算NDCG\n",
    "            if idcg > 0:\n",
    "                ndcg_sum += dcg / idcg\n",
    "    \n",
    "    return ndcg_sum / total\n",
    "\n",
    "def evaluate_predictions(cands_df, label_df, score_col='pre_score', k=50):\n",
    "    \"\"\"\n",
    "    评估预测结果\n",
    "    \n",
    "    Args:\n",
    "        cands_df: 候选DataFrame，包含 buyer_admin_id, item_id, score_col\n",
    "        label_df: 标签DataFrame，包含 buyer_admin_id, label_item\n",
    "        score_col: 评分列名\n",
    "        k: Top-K\n",
    "        \n",
    "    Returns:\n",
    "        dict: 评估指标\n",
    "    \"\"\"\n",
    "    print(f\"📊 评估预测结果 (K={k}, score_col={score_col})...\")\n",
    "    \n",
    "    # 构建真实标签字典\n",
    "    y_true = dict(zip(label_df['buyer_admin_id'], label_df['label_item']))\n",
    "    \n",
    "    # 构建预测结果字典\n",
    "    y_pred = {}\n",
    "    cands_sorted = cands_df.sort_values(['buyer_admin_id', score_col], ascending=[True, False])\n",
    "    \n",
    "    for user_id, group in cands_sorted.groupby('buyer_admin_id'):\n",
    "        y_pred[user_id] = group['item_id'].tolist()\n",
    "    \n",
    "    # 计算指标\n",
    "    recall = recall_at_k(y_true, y_pred, k)\n",
    "    ndcg = ndcg_at_k(y_true, y_pred, k)\n",
    "    \n",
    "    # 覆盖率统计\n",
    "    pred_users = set(y_pred.keys())\n",
    "    true_users = set(y_true.keys())\n",
    "    coverage = len(pred_users & true_users) / len(true_users)\n",
    "    \n",
    "    metrics = {\n",
    "        f'recall@{k}': recall,\n",
    "        f'ndcg@{k}': ndcg,\n",
    "        'coverage': coverage,\n",
    "        'total_users': len(true_users),\n",
    "        'pred_users': len(pred_users)\n",
    "    }\n",
    "    \n",
    "    print(f\"  📈 Recall@{k}: {recall:.4f}\")\n",
    "    print(f\"  📈 NDCG@{k}: {ndcg:.4f}\")\n",
    "    print(f\"  📊 覆盖率: {coverage:.4f}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "print(\"✅ 评估函数定义完成\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcf7465",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 准备数据 ===\n",
    "cm = add_common_feats(add_label(cands_covisit.copy()))\n",
    "mm = add_common_feats(add_label(cands_multi.copy()))\n",
    "\n",
    "# A1: No-Rank baselines（pred = pre_score）\n",
    "cm_nr = cm.copy(); cm_nr['pred'] = cm_nr['pre_score']\n",
    "mm_nr = mm.copy(); mm_nr['pred'] = mm_nr['pre_score']\n",
    "\n",
    "mA1 = {\n",
    "    'covisit_only_NoRank': dict(\n",
    "        recall_at_50 = round(recall_at_k(cm_nr, 50), 6),\n",
    "        ndcg_at_50   = round(ndcg_at_k(cm_nr, 50), 6)\n",
    "    ),\n",
    "    'multi_NoRank': dict(\n",
    "        recall_at_50 = round(recall_at_k(mm_nr, 50), 6),\n",
    "        ndcg_at_50   = round(ndcg_at_k(mm_nr, 50), 6)\n",
    "    )\n",
    "}\n",
    "mA1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68699712",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === A2: Multi + Ranker ===\n",
    "feat_cols = ['score_rebuy','score_covisit','is_cate_hot','is_store_hot','is_global_pop',\n",
    "             'src_count','user_hist_cnt','item_pop_cnt','pre_score']\n",
    "\n",
    "# LightGBM 优先，无法使用则降级 RF\n",
    "try:\n",
    "    from lightgbm import LGBMClassifier\n",
    "    has_lgbm = True\n",
    "except Exception:\n",
    "    has_lgbm = False\n",
    "    from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "\n",
    "if has_lgbm:\n",
    "    model = LGBMClassifier(n_estimators=400, learning_rate=0.05,\n",
    "                           num_leaves=63, subsample=0.8, colsample_bytree=0.8,\n",
    "                           random_state=2025)\n",
    "else:\n",
    "    model = RFC(n_estimators=300, random_state=2025, n_jobs=-1)\n",
    "\n",
    "X = mm[feat_cols].values\n",
    "y = mm['label'].values\n",
    "model.fit(X, y)\n",
    "\n",
    "mm_rank = mm.copy()\n",
    "if hasattr(model, 'predict_proba'):\n",
    "    mm_rank['pred'] = model.predict_proba(mm[feat_cols])[:,1]\n",
    "elif hasattr(model, 'decision_function'):\n",
    "    v = model.decision_function(mm[feat_cols])\n",
    "    mm_rank['pred'] = (v - v.min())/(v.max()-v.min()+1e-9)\n",
    "else:\n",
    "    mm_rank['pred'] = model.predict(mm[feat_cols]).astype(float)\n",
    "\n",
    "mA2 = {\n",
    "    'multi_Ranker': dict(\n",
    "        recall_at_50 = round(recall_at_k(mm_rank, 50), 6),\n",
    "        ndcg_at_50   = round(ndcg_at_k(mm_rank, 50), 6)\n",
    "    )\n",
    "}\n",
    "mA2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c922b993",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 保存指标、明细、模型、特征重要性 ===\n",
    "import pandas as pd, numpy as np, os, joblib\n",
    "\n",
    "metrics = pd.DataFrame([\n",
    "    dict(setting='A1_covisit_only_NoRank', **mA1['covisit_only_NoRank']),\n",
    "    dict(setting='A1_multi_NoRank',        **mA1['multi_NoRank']),\n",
    "    dict(setting='A2_multi_Ranker',        **mA2['multi_Ranker']),\n",
    "])\n",
    "metrics.to_csv(f'{OUTDIR}/metrics_ablation.csv', index=False)\n",
    "\n",
    "mm_nr.to_parquet(f'{OUTDIR}/mm_norank.parquet', index=False)\n",
    "mm_rank.to_parquet(f'{OUTDIR}/mm_rank.parquet', index=False)\n",
    "cm_nr.to_parquet(f'{OUTDIR}/cm_norank.parquet', index=False)\n",
    "\n",
    "# 保存模型（统一文件名，便于 4_online 自动加载）\n",
    "model_path = os.path.join(OUTDIR, 'model_lgb.pkl')\n",
    "joblib.dump(model, model_path)\n",
    "print('Model saved to', model_path)\n",
    "\n",
    "# 特征重要性（若可用）\n",
    "fi_path = os.path.join(OUTDIR, 'feature_importance.csv')\n",
    "if hasattr(model, 'feature_importances_'):\n",
    "    importances = getattr(model, 'feature_importances_')\n",
    "    pd.DataFrame({'feature': feat_cols, 'importance': importances})       .sort_values('importance', ascending=False).to_csv(fi_path, index=False)\n",
    "    print('Feature importance saved to', fi_path)\n",
    "else:\n",
    "    print('Model has no feature_importances_; skip.')\n",
    "\n",
    "print('\\nMetrics:'); print(metrics)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
