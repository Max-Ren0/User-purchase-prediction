{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "132f17dc",
   "metadata": {},
   "source": [
    "# 1) 多路召回（加速版）\n",
    "本 Notebook 是对原来的 `1_recall.ipynb` 的**性能优化替换**：\n",
    "- 新增 **FAST_MODE**（小参数先冒烟）\n",
    "- 压缩 `dtype` 降内存\n",
    "- 预计算：共现邻接表 / 最近K / 用户偏好槽位 / 热榜字典 / 复购映射\n",
    "- 候选构建改为**纯字典 + numpy 批处理**（避免频繁 `merge/iterrows`）\n",
    "- 输出与原版一致：统计表 + 两套候选（多路 vs 仅共现）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d80edcd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vis rows: 6506700  users: 483117\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, pandas as pd, numpy as np\n",
    "\n",
    "# 输入/输出目录\n",
    "OUTDIR = '../x'\n",
    "assert os.path.exists(f'{OUTDIR}/train_vis.parquet'), \"请先运行 0_prep.ipynb\"\n",
    "train_vis = pd.read_parquet(f'{OUTDIR}/train_vis.parquet')\n",
    "label_df  = pd.read_parquet(f'{OUTDIR}/label_df.parquet')\n",
    "item_attr = pd.read_parquet(f'{OUTDIR}/item_attr.parquet')\n",
    "\n",
    "# 进度条（无则优雅退化）\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except Exception:\n",
    "    def tqdm(x, **k): return x\n",
    "\n",
    "# 参数\n",
    "PARAMS = dict(\n",
    "    covisit_window=3,           # 共现滑窗(3或5)\n",
    "    covisit_top_per_a=200,      # 每个a保留TopK出边\n",
    "    recent_k=5,                 # 最近K个item作为共现起点\n",
    "    cand_per_recent=40,         # 每个起点取TopN下游\n",
    "    tau_days=14,                # 复购时间衰减(天)\n",
    "    user_top_cates=3,           # 用户偏好类目TopN\n",
    "    user_top_stores=3,          # 用户偏好店铺TopN\n",
    "    per_cate_pool=80,           # 每个偏好类目热门池\n",
    "    per_store_pool=60,          # 每个偏好店铺热门池\n",
    "    pop_pool=2000,              # 全局热门池大小\n",
    "    recall_cap=600,             # 单用户候选上限\n",
    ")\n",
    "\n",
    "# —— 快车模式（先跑通，再关掉恢复全量） ——\n",
    "FAST_MODE = True\n",
    "if FAST_MODE:\n",
    "    PARAMS.update({\n",
    "        'covisit_top_per_a': 120,\n",
    "        'recent_k': 3,\n",
    "        'cand_per_recent': 24,\n",
    "        'per_cate_pool': 40,\n",
    "        'per_store_pool': 40,\n",
    "        'pop_pool': 1000,\n",
    "        'recall_cap': 400,\n",
    "    })\n",
    "\n",
    "# 压缩整数类型，减少内存/IO\n",
    "for df in (train_vis, item_attr):\n",
    "    for c in ('buyer_admin_id','item_id'):\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], downcast='integer')\n",
    "    for c in ('cate_id','store_id'):\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], downcast='integer')\n",
    "\n",
    "print(\"train_vis rows:\", len(train_vis), \" users:\", train_vis['buyer_admin_id'].nunique())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cc886a",
   "metadata": {},
   "source": [
    "# --- 复购评分 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d718dd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def time_decay(days, tau=14.0):\n",
    "    days = np.maximum(days, 0.0)\n",
    "    return np.exp(-days / float(tau))\n",
    "\n",
    "def build_rebuy_scores(df, tau_days=14):\n",
    "    g = df.copy()\n",
    "    ref = g.groupby('buyer_admin_id')['create_order_time'].transform('max')\n",
    "    g['days_ago'] = (ref - g['create_order_time']).dt.days.clip(lower=0)\n",
    "    g['score_rebuy'] = time_decay(g['days_ago'].to_numpy(), tau=tau_days)\n",
    "    return (g.groupby(['buyer_admin_id','item_id'])['score_rebuy']\n",
    "              .sum().reset_index())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c3e0ee",
   "metadata": {},
   "source": [
    "# --- 共现图 a->b ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c8c972",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_covisit(df, W=3, topk=200):\n",
    "    base = df[['buyer_admin_id','item_id']].copy()\n",
    "    pairs = []\n",
    "    for lag in range(1, W+1):\n",
    "        t = base.copy()\n",
    "        t['item_b'] = t.groupby('buyer_admin_id')['item_id'].shift(-lag)\n",
    "        t = t.dropna().rename(columns={'item_id':'item_a'})\n",
    "        t['w'] = 1.0/lag\n",
    "        pairs.append(t[['item_a','item_b','w']])\n",
    "    if not pairs:\n",
    "        return pd.DataFrame(columns=['item_a','item_b','w'])\n",
    "    co = pd.concat(pairs, ignore_index=True)\n",
    "    co = co.groupby(['item_a','item_b'])['w'].sum().reset_index()\n",
    "    co['rn'] = co.groupby('item_a')['w'].rank(ascending=False, method='first')\n",
    "    return co[co['rn']<=topk].drop(columns='rn')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08c4d28",
   "metadata": {},
   "source": [
    "# --- 热门池（全局/类目/店铺） ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f115f087",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def build_pop_pools(df, item_attr, pop_pool=2000):\n",
    "    pop = df.groupby('item_id').size().rename('pop').reset_index()\n",
    "\n",
    "    cate_pop = (df.merge(item_attr, on='item_id', how='left')\n",
    "                .groupby(['cate_id','item_id']).size().rename('pop').reset_index())\n",
    "    cate_pop['rn'] = cate_pop.groupby('cate_id')['pop'].rank(ascending=False, method='first')\n",
    "\n",
    "    store_pop = (df.merge(item_attr, on='item_id', how='left')\n",
    "                 .groupby(['store_id','item_id']).size().rename('pop').reset_index())\n",
    "    store_pop['rn'] = store_pop.groupby('store_id')['pop'].rank(ascending=False, method='first')\n",
    "\n",
    "    global_pop = pop.sort_values('pop', ascending=False).head(pop_pool)\n",
    "    return cate_pop, store_pop, global_pop\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a93933",
   "metadata": {},
   "source": [
    "# --- 构建统计 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f9d6899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stats saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rebuy = build_rebuy_scores(train_vis, tau_days=PARAMS['tau_days'])\n",
    "covisit = build_covisit(train_vis, W=PARAMS['covisit_window'], topk=PARAMS['covisit_top_per_a'])\n",
    "cate_pop, store_pop, global_pop = build_pop_pools(train_vis, item_attr, pop_pool=PARAMS['pop_pool'])\n",
    "\n",
    "# 保存统计表（snappy 压缩更快）\n",
    "rebuy.to_parquet(f'{OUTDIR}/rebuy.parquet', index=False, compression='snappy')\n",
    "covisit.to_parquet(f'{OUTDIR}/covisit.parquet', index=False, compression='snappy')\n",
    "cate_pop.to_parquet(f'{OUTDIR}/cate_pop.parquet', index=False, compression='snappy')\n",
    "store_pop.to_parquet(f'{OUTDIR}/store_pop.parquet', index=False, compression='snappy')\n",
    "global_pop.to_parquet(f'{OUTDIR}/global_pop.parquet', index=False, compression='snappy')\n",
    "\n",
    "print(\"stats saved.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f459ead3",
   "metadata": {},
   "source": [
    "# --- 预计算映射：显著加速候选构建 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc7632bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precomputed maps ready.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "P = PARAMS  # 简写\n",
    "\n",
    "# 1) 共现邻接 a -> (b[], w[])\n",
    "cov_neighbors = {}\n",
    "for a, g in covisit.groupby('item_a'):\n",
    "    sub = g[['item_b','w']].head(P['cand_per_recent']).to_numpy()\n",
    "    if len(sub):\n",
    "        cov_neighbors[int(a)] = (sub[:,0].astype('int64'), sub[:,1].astype('float32'))\n",
    "\n",
    "# 2) 每用户最近K个item\n",
    "recent_map = (train_vis.sort_values('create_order_time')\n",
    "              .groupby('buyer_admin_id')['item_id']\n",
    "              .apply(lambda s: s.tail(P['recent_k']).to_numpy('int64'))\n",
    "              ).to_dict()\n",
    "\n",
    "# 3) 用户偏好类目/店铺 TopN\n",
    "ua = train_vis.merge(item_attr, on='item_id', how='left')\n",
    "user_topc = ua.groupby('buyer_admin_id')['cate_id']               .apply(lambda s: s.value_counts().head(P['user_top_cates']).index.to_numpy('int64')).to_dict()\n",
    "user_tops = ua.groupby('buyer_admin_id')['store_id']               .apply(lambda s: s.value_counts().head(P['user_top_stores']).index.to_numpy('int64')).to_dict()\n",
    "\n",
    "# 4) 类目/店铺热榜池预展平\n",
    "cate_top = {int(c): grp.loc[grp['rn']<=P['per_cate_pool'],'item_id'].to_numpy('int64')\n",
    "            for c, grp in cate_pop.groupby('cate_id')}\n",
    "store_top = {int(s): grp.loc[grp['rn']<=P['per_store_pool'],'item_id'].to_numpy('int64')\n",
    "             for s, grp in store_pop.groupby('store_id')}\n",
    "global_items = global_pop['item_id'].to_numpy('int64')\n",
    "\n",
    "# 5) 复购映射：user -> (items[], weights[])\n",
    "rebuy_map = {}\n",
    "for uid, g in rebuy.groupby('buyer_admin_id'):\n",
    "    rebuy_map[int(uid)] = (g['item_id'].to_numpy('int64'),\n",
    "                           g['score_rebuy'].to_numpy('float32'))\n",
    "\n",
    "print(\"precomputed maps ready.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3943839",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 快速候选构建 ---\n",
    "def build_candidates_fast(uid,\n",
    "                          use_rebuy=True, use_covisit=True,\n",
    "                          use_cate_store=True, use_global=True):\n",
    "    cand = {}\n",
    "\n",
    "    # 路1：复购\n",
    "    if use_rebuy and uid in rebuy_map:\n",
    "        items, ws = rebuy_map[uid]\n",
    "        for it, w in zip(items, ws):\n",
    "            cand.setdefault(int(it), []).append(('rebuy', float(w)))\n",
    "\n",
    "    # 路2：共现（最近K个起点）\n",
    "    if use_covisit:\n",
    "        for a in recent_map.get(uid, []):\n",
    "            pair = cov_neighbors.get(int(a))\n",
    "            if pair is None: \n",
    "                continue\n",
    "            bs, ws = pair\n",
    "            for b, w in zip(bs, ws):\n",
    "                cand.setdefault(int(b), []).append(('covisit', float(w)))\n",
    "\n",
    "    # 路3：类目/店铺热门（用户偏好槽位）\n",
    "    if use_cate_store:\n",
    "        for c in user_topc.get(uid, []):\n",
    "            for it in cate_top.get(int(c), ()):\n",
    "                cand.setdefault(int(it), []).append(('cate_hot', 1.0))\n",
    "        for s in user_tops.get(uid, []):\n",
    "            for it in store_top.get(int(s), ()):\n",
    "                cand.setdefault(int(it), []).append(('store_hot', 1.0))\n",
    "\n",
    "    # 路4：全局热门兜底\n",
    "    if use_global:\n",
    "        for it in global_items:\n",
    "            cand.setdefault(int(it), []).append(('global_pop', 1.0))\n",
    "\n",
    "    # 汇总来源与预打分\n",
    "    if not cand:\n",
    "        cols = ['buyer_admin_id','item_id','score_rebuy','score_covisit',\n",
    "                'is_cate_hot','is_store_hot','is_global_pop','src_count','pre_score']\n",
    "        return pd.DataFrame(columns=cols)\n",
    "\n",
    "    rows = []\n",
    "    for it, srcs in cand.items():\n",
    "        srcset = set()\n",
    "        sr = 0.0; sc = 0.0\n",
    "        is_cate = 0; is_store = 0; is_glob = 0\n",
    "        for tag, w in srcs:\n",
    "            srcset.add(tag)\n",
    "            if tag == 'rebuy': sr = max(sr, w)\n",
    "            elif tag == 'covisit': sc = max(sc, w)\n",
    "            elif tag == 'cate_hot': is_cate = 1\n",
    "            elif tag == 'store_hot': is_store = 1\n",
    "            elif tag == 'global_pop': is_glob = 1\n",
    "        rows.append((int(uid), int(it), float(sr), float(sc),\n",
    "                     is_cate, is_store, is_glob, len(srcset)))\n",
    "    arr = np.asarray(rows, dtype=object)\n",
    "    cdf = pd.DataFrame(arr, columns=[\n",
    "        'buyer_admin_id','item_id','score_rebuy','score_covisit',\n",
    "        'is_cate_hot','is_store_hot','is_global_pop','src_count'\n",
    "    ])\n",
    "    cdf['pre_score'] = (cdf['score_rebuy'] + cdf['score_covisit']\n",
    "                        + 0.3*cdf['is_cate_hot'] + 0.3*cdf['is_store_hot'] + 0.1*cdf['is_global_pop'])\n",
    "    return cdf.sort_values('pre_score', ascending=False).head(PARAMS['recall_cap'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa047421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAST_MODE: only first 5000 users for smoke test.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build candidates (fast): 100%|██████████| 5000/5000 [00:07<00:00, 634.89user/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved recall artifacts to ../x\n",
      "multi: (2000000, 9) covisit_only: (180814, 9)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 生成候选（多路 vs 仅共现，用于消融） ---\n",
    "val_users = label_df['buyer_admin_id'].unique()\n",
    "\n",
    "# 快车模式：如数据很大，先抽前 N 个用户冒烟\n",
    "if FAST_MODE:\n",
    "    N_SMOKE = 5000\n",
    "    if len(val_users) > N_SMOKE:\n",
    "        val_users = val_users[:N_SMOKE]\n",
    "        print(f\"FAST_MODE: only first {N_SMOKE} users for smoke test.\")\n",
    "\n",
    "multi_list, covis_list = [], []\n",
    "for uid in tqdm(val_users, desc='build candidates (fast)', unit='user'):\n",
    "    multi_list.append(build_candidates_fast(int(uid), True, True, True, True))\n",
    "    covis_list.append(build_candidates_fast(int(uid), False, True, False, False))\n",
    "\n",
    "cands_multi   = pd.concat(multi_list, ignore_index=True) if multi_list else                 pd.DataFrame(columns=['buyer_admin_id','item_id','score_rebuy','score_covisit','is_cate_hot','is_store_hot','is_global_pop','src_count','pre_score'])\n",
    "cands_covisit = pd.concat(covis_list, ignore_index=True) if covis_list else                 pd.DataFrame(columns=['buyer_admin_id','item_id','score_rebuy','score_covisit','is_cate_hot','is_store_hot','is_global_pop','src_count','pre_score'])\n",
    "\n",
    "# 保存候选\n",
    "cands_multi.to_parquet(f'{OUTDIR}/cands_multi.parquet', index=False, compression='snappy')\n",
    "cands_covisit.to_parquet(f'{OUTDIR}/cands_covisit_only.parquet', index=False, compression='snappy')\n",
    "\n",
    "print('Saved recall artifacts to', OUTDIR)\n",
    "print('multi:', cands_multi.shape, 'covisit_only:', cands_covisit.shape)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
