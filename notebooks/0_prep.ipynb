{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1097718a",
   "metadata": {},
   "source": [
    "# 📊 数据预处理模块 (0_prep.ipynb)\n",
    "\n",
    "## 🎯 模块目标\n",
    "本模块负责原始数据的加载、清洗和预处理，为后续的召回和排序模块提供标准化的数据输入。\n",
    "\n",
    "## 📋 主要功能\n",
    "1. **数据加载**: 读取训练集、测试集和商品属性数据\n",
    "2. **数据排序**: 按用户ID、时间、排序字段进行标准化排序\n",
    "3. **数据验证**: 检查必要字段的完整性和正确性\n",
    "4. **留一验证**: 科学的时序切分，避免数据泄漏\n",
    "5. **数据保存**: 生成标准化的中间文件供后续使用\n",
    "\n",
    "## 🔧 输出文件\n",
    "- `train_sorted.parquet`: 排序后的完整训练数据\n",
    "- `test_sorted.parquet`: 排序后的测试数据  \n",
    "- `train_vis.parquet`: 用于离线统计的训练数据（去除标签）\n",
    "- `label_df.parquet`: 留一验证的标签数据\n",
    "- `item_attr.parquet`: 清洗后的商品属性数据\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf88d21e",
   "metadata": {},
   "source": [
    "## 1️⃣ 环境配置与依赖导入\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a03171f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 环境配置完成\n",
      "📁 输出目录: ../x\n",
      "⏰ 处理时间: 2025-09-10 21:36:24\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 依赖库导入\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# =============================================================================\n",
    "# 配置参数\n",
    "# =============================================================================\n",
    "# 数据文件路径\n",
    "TRAIN_CSV = '../data/Antai_hackathon_train.csv'\n",
    "TEST_CSV  = '../data/dianshang_test.csv'\n",
    "ATTR_CSV  = '../data/Antai_hackathon_attr.csv'\n",
    "\n",
    "# 输出目录\n",
    "OUTDIR = '../x'\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "print(\"✅ 环境配置完成\")\n",
    "print(f\"📁 输出目录: {OUTDIR}\")\n",
    "print(f\"⏰ 处理时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903d94a8",
   "metadata": {},
   "source": [
    "## 2️⃣ 数据类型定义与加载\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acc0a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 数据类型定义完成\n",
      "💾 使用int32/int16减少内存占用\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 数据类型定义 - 内存优化\n",
    "# =============================================================================\n",
    "dtype_train = {\n",
    "    \"buyer_admin_id\": \"int32\",    # 用户ID\n",
    "    \"item_id\": \"int32\",           # 商品ID\n",
    "    \"irank\": \"int16\"              # 排序字段\n",
    "}\n",
    "\n",
    "dtype_test = {\n",
    "    \"buyer_admin_id\": \"int32\",\n",
    "    \"item_id\": \"int32\",\n",
    "    \"irank\": \"int16\"\n",
    "}\n",
    "\n",
    "dtype_item_attr = {\n",
    "    \"item_id\": \"int32\",\n",
    "    \"cate_id\": \"int32\", \n",
    "    \"store_id\": \"int32\"\n",
    "}\n",
    "\n",
    "print(\"📋 数据类型定义完成\")\n",
    "print(\"💾 使用int32/int16减少内存占用\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4c28e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 正在加载数据文件...\n",
      "  📖 加载训练数据...\n",
      "  📖 加载测试数据...\n",
      "  📖 加载商品属性数据...\n",
      "✅ 数据加载完成\n",
      "📊 训练集: (6989817, 5)\n",
      "📊 测试集: (140380, 5)\n",
      "📊 商品属性: (1924269, 4)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 数据加载\n",
    "# =============================================================================\n",
    "print(\"🔄 正在加载数据文件...\")\n",
    "\n",
    "# 加载训练数据\n",
    "print(\"  📖 加载训练数据...\")\n",
    "train = pd.read_csv(\n",
    "    TRAIN_CSV,\n",
    "    parse_dates=['create_order_time'],  # 时间字段自动解析\n",
    "    dtype=dtype_train\n",
    ")\n",
    "\n",
    "# 加载测试数据  \n",
    "print(\"  📖 加载测试数据...\")\n",
    "test = pd.read_csv(\n",
    "    TEST_CSV,\n",
    "    parse_dates=['create_order_time'],\n",
    "    dtype=dtype_test\n",
    ")\n",
    "\n",
    "# 加载商品属性数据\n",
    "print(\"  📖 加载商品属性数据...\")\n",
    "item_attr = pd.read_csv(\n",
    "    ATTR_CSV,\n",
    "    dtype=dtype_item_attr\n",
    ")\n",
    "\n",
    "print(\"✅ 数据加载完成\")\n",
    "print(f\"📊 训练集: {train.shape}\")\n",
    "print(f\"📊 测试集: {test.shape}\")  \n",
    "print(f\"📊 商品属性: {item_attr.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f3eae3",
   "metadata": {},
   "source": [
    "## 3️⃣ 数据质量检查\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9ff690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 开始数据质量检查...\n",
      "✅ 数据字段完整性检查通过\n",
      "\n",
      "📈 数据基础统计:\n",
      "  👥 用户数量: 483,117\n",
      "  🛍️ 商品数量: 1,852,506\n",
      "  📦 商品属性数量: 1,924,269\n",
      "  📅 时间范围: 2018-03-13 04:01:00 ~ 2018-04-28 23:59:57\n",
      "\n",
      "🔍 缺失值检查:\n",
      "  训练数据缺失值: 0\n",
      "  测试数据缺失值: 0\n",
      "  商品属性缺失值: 0\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 数据完整性检查\n",
    "# =============================================================================\n",
    "print(\"🔍 开始数据质量检查...\")\n",
    "\n",
    "# 定义必需字段\n",
    "REQUIRED_TRAIN_COLS = {'buyer_admin_id', 'item_id', 'create_order_time', 'irank'}\n",
    "REQUIRED_ATTR_COLS = {'item_id', 'cate_id', 'store_id'}\n",
    "\n",
    "# 检查训练数据字段\n",
    "missing_train = REQUIRED_TRAIN_COLS - set(train.columns)\n",
    "missing_test = REQUIRED_TRAIN_COLS - set(test.columns)\n",
    "missing_attr = REQUIRED_ATTR_COLS - set(item_attr.columns)\n",
    "\n",
    "# 断言检查\n",
    "assert len(missing_train) == 0, f'❌ 训练数据缺少字段: {missing_train}'\n",
    "assert len(missing_test) == 0, f'❌ 测试数据缺少字段: {missing_test}'\n",
    "assert len(missing_attr) == 0, f'❌ 商品属性缺少字段: {missing_attr}'\n",
    "\n",
    "print(\"✅ 数据字段完整性检查通过\")\n",
    "\n",
    "# 基础统计信息\n",
    "print(\"\\n📈 数据基础统计:\")\n",
    "print(f\"  👥 用户数量: {train['buyer_admin_id'].nunique():,}\")\n",
    "print(f\"  🛍️ 商品数量: {train['item_id'].nunique():,}\")\n",
    "print(f\"  📦 商品属性数量: {item_attr.shape[0]:,}\")\n",
    "print(f\"  📅 时间范围: {train['create_order_time'].min()} ~ {train['create_order_time'].max()}\")\n",
    "\n",
    "# 检查缺失值\n",
    "print(f\"\\n🔍 缺失值检查:\")\n",
    "print(f\"  训练数据缺失值: {train.isnull().sum().sum()}\")\n",
    "print(f\"  测试数据缺失值: {test.isnull().sum().sum()}\")\n",
    "print(f\"  商品属性缺失值: {item_attr.isnull().sum().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2a079b",
   "metadata": {},
   "source": [
    "## 4️⃣ 数据排序与标准化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749b958c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 正在进行数据排序...\n",
      "✅ 数据排序完成\n",
      "📋 排序字段: buyer_admin_id → create_order_time → irank\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 数据排序标准化\n",
    "# =============================================================================\n",
    "print(\"🔄 正在进行数据排序...\")\n",
    "\n",
    "# 确保数据按时序正确排序\n",
    "# 排序规则: 用户ID -> 时间 -> irank (升序)\n",
    "train = train.sort_values(\n",
    "    ['buyer_admin_id', 'create_order_time', 'irank']\n",
    ").reset_index(drop=True)\n",
    "\n",
    "test = test.sort_values(\n",
    "    ['buyer_admin_id', 'create_order_time', 'irank']\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(\"✅ 数据排序完成\")\n",
    "print(\"📋 排序字段: buyer_admin_id → create_order_time → irank\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f755b71",
   "metadata": {},
   "source": [
    "## 5️⃣ 留一验证切分\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dff7d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 开始留一验证切分...\n",
      "✅ 留一验证切分完成\n",
      "📊 原始训练数据: 6,989,817 条\n",
      "📊 训练可视数据: 6,506,700 条\n",
      "📊 标签数据: 483,117 条\n",
      "👥 参与验证的用户: 483,117 人\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 留一验证切分 - 避免数据泄漏\n",
    "# =============================================================================\n",
    "print(\"🔄 开始留一验证切分...\")\n",
    "\n",
    "# 找到每个用户的最后一条购买记录作为标签\n",
    "# 注意: 这里使用idxmin()是因为排序后第一条是最早的记录\n",
    "# 我们需要最后一条记录，所以使用idxmax()\n",
    "last_idx = train.groupby('buyer_admin_id')['irank'].idxmax()\n",
    "\n",
    "# 创建标签数据集\n",
    "label_df = train.loc[last_idx, ['buyer_admin_id', 'item_id']].copy()\n",
    "label_df = label_df.rename(columns={'item_id': 'label_item'})\n",
    "\n",
    "# 创建训练可视数据集（去除标签数据，防止泄漏）\n",
    "train_vis = train.drop(index=last_idx).copy()\n",
    "\n",
    "print(\"✅ 留一验证切分完成\")\n",
    "print(f\"📊 原始训练数据: {train.shape[0]:,} 条\")\n",
    "print(f\"📊 训练可视数据: {train_vis.shape[0]:,} 条\")\n",
    "print(f\"📊 标签数据: {label_df.shape[0]:,} 条\")\n",
    "print(f\"👥 参与验证的用户: {label_df['buyer_admin_id'].nunique():,} 人\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87af2d73",
   "metadata": {},
   "source": [
    "## 6️⃣ 数据保存与输出\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffbba5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 正在保存处理后的数据...\n",
      "  ✅ 保存完整训练数据: train_sorted.parquet\n",
      "  ✅ 保存测试数据: test_sorted.parquet\n",
      "  ✅ 保存商品属性数据: item_attr.parquet\n",
      "  ✅ 保存训练可视数据: train_vis.parquet\n",
      "  ✅ 保存标签数据: label_df.parquet\n",
      "\n",
      "🎉 数据预处理完成！\n",
      "📁 所有文件已保存到: ../x\n",
      "📊 最终数据规模总结:\n",
      "  - 完整训练数据: (6989817, 5)\n",
      "  - 测试数据: (140380, 5)\n",
      "  - 训练可视数据: (6506700, 5)\n",
      "  - 标签数据: (483117, 2)\n",
      "  - 商品属性数据: (1924269, 3)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 数据保存 - 生成标准化的中间文件\n",
    "# =============================================================================\n",
    "print(\"💾 正在保存处理后的数据...\")\n",
    "\n",
    "# 保存训练数据（完整版）\n",
    "train.to_parquet(f'{OUTDIR}/train_sorted.parquet', index=False)\n",
    "print(f\"  ✅ 保存完整训练数据: train_sorted.parquet\")\n",
    "\n",
    "# 保存测试数据\n",
    "test.to_parquet(f'{OUTDIR}/test_sorted.parquet', index=False)\n",
    "print(f\"  ✅ 保存测试数据: test_sorted.parquet\")\n",
    "\n",
    "# 保存商品属性数据（去重后）\n",
    "item_attr_clean = item_attr[['item_id', 'cate_id', 'store_id']].drop_duplicates()\n",
    "item_attr_clean.to_parquet(f'{OUTDIR}/item_attr.parquet', index=False)\n",
    "print(f\"  ✅ 保存商品属性数据: item_attr.parquet\")\n",
    "\n",
    "# 保存训练可视数据（用于离线统计）\n",
    "train_vis.to_parquet(f'{OUTDIR}/train_vis.parquet', index=False)\n",
    "print(f\"  ✅ 保存训练可视数据: train_vis.parquet\")\n",
    "\n",
    "# 保存标签数据\n",
    "label_df.to_parquet(f'{OUTDIR}/label_df.parquet', index=False)\n",
    "print(f\"  ✅ 保存标签数据: label_df.parquet\")\n",
    "\n",
    "print(f\"\\n🎉 数据预处理完成！\")\n",
    "print(f\"📁 所有文件已保存到: {OUTDIR}\")\n",
    "print(f\"📊 最终数据规模总结:\")\n",
    "print(f\"  - 完整训练数据: {train.shape}\")\n",
    "print(f\"  - 测试数据: {test.shape}\")\n",
    "print(f\"  - 训练可视数据: {train_vis.shape}\")\n",
    "print(f\"  - 标签数据: {label_df.shape}\")\n",
    "print(f\"  - 商品属性数据: {item_attr_clean.shape}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
