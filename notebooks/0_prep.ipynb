{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1097718a",
   "metadata": {},
   "source": [
    "# 📊 数据预处理模块 (0_prep.ipynb)\n",
    "\n",
    "## 🎯 模块目标\n",
    "本模块负责原始数据的加载、清洗和预处理，为后续的召回和排序模块提供标准化的数据输入。\n",
    "\n",
    "## 📋 主要功能\n",
    "1. **数据加载**: 读取训练集、测试集和商品属性数据\n",
    "2. **数据排序**: 按用户ID、时间、排序字段进行标准化排序\n",
    "3. **数据验证**: 检查必要字段的完整性和正确性\n",
    "4. **留一验证**: 科学的时序切分，避免数据泄漏\n",
    "5. **数据保存**: 生成标准化的中间文件供后续使用\n",
    "\n",
    "## 🔧 输出文件\n",
    "- `train_sorted.parquet`: 排序后的完整训练数据\n",
    "- `test_sorted.parquet`: 排序后的测试数据  \n",
    "- `train_vis.parquet`: 用于离线统计的训练数据（去除标签）\n",
    "- `label_df.parquet`: 留一验证的标签数据\n",
    "- `item_attr.parquet`: 清洗后的商品属性数据\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf88d21e",
   "metadata": {},
   "source": [
    "## 1️⃣ 环境配置与依赖导入\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a03171f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T14:56:35.800536Z",
     "iopub.status.busy": "2025-09-15T14:56:35.800337Z",
     "iopub.status.idle": "2025-09-15T14:56:36.428338Z",
     "shell.execute_reply": "2025-09-15T14:56:36.428072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 环境配置完成\n",
      "📁 输出目录: ../x\n",
      "🎯 抽样模式: 启用\n",
      "👥 目标用户数: 10,000\n",
      "⏰ 处理时间: 2025-09-26 15:50:54\n",
      "✅ 环境配置完成\n",
      "📁 输出目录: ../x\n",
      "⏰ 处理时间: 2025-09-26 15:50:54\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 依赖库导入\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# 添加项目根目录到路径，以便导入自定义模块\n",
    "sys.path.append('..')\n",
    "\n",
    "# =============================================================================\n",
    "# 配置参数\n",
    "# =============================================================================\n",
    "# 数据文件路径\n",
    "TRAIN_CSV = '../data/Antai_hackathon_train.csv'\n",
    "TEST_CSV  = '../data/dianshang_test.csv'\n",
    "ATTR_CSV  = '../data/Antai_hackathon_attr.csv'\n",
    "\n",
    "# 输出目录\n",
    "OUTDIR = '../x'\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "# =============================================================================\n",
    "# 抽样配置\n",
    "# =============================================================================\n",
    "# 是否启用智能抽样\n",
    "ENABLE_SAMPLING = True\n",
    "TARGET_USERS = 10000  # 目标用户数量\n",
    "SAMPLING_SEED = 42    # 随机种子\n",
    "\n",
    "print(\"✅ 环境配置完成\")\n",
    "print(f\"📁 输出目录: {OUTDIR}\")\n",
    "print(f\"🎯 抽样模式: {'启用' if ENABLE_SAMPLING else '禁用'}\")\n",
    "if ENABLE_SAMPLING:\n",
    "    print(f\"👥 目标用户数: {TARGET_USERS:,}\")\n",
    "print(f\"⏰ 处理时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "print(\"✅ 环境配置完成\")\n",
    "print(f\"📁 输出目录: {OUTDIR}\")\n",
    "print(f\"⏰ 处理时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903d94a8",
   "metadata": {},
   "source": [
    "## 2️⃣ 数据类型定义与加载\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8acc0a02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T14:56:36.429550Z",
     "iopub.status.busy": "2025-09-15T14:56:36.429433Z",
     "iopub.status.idle": "2025-09-15T14:56:36.431380Z",
     "shell.execute_reply": "2025-09-15T14:56:36.431205Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 数据类型定义完成\n",
      "💾 使用int32/int16减少内存占用\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 数据类型定义 - 内存优化\n",
    "# =============================================================================\n",
    "dtype_train = {\n",
    "    \"buyer_admin_id\": \"int32\",    # 用户ID\n",
    "    \"item_id\": \"int32\",           # 商品ID\n",
    "    \"irank\": \"int16\"              # 排序字段\n",
    "}\n",
    "\n",
    "dtype_test = {\n",
    "    \"buyer_admin_id\": \"int32\",\n",
    "    \"item_id\": \"int32\",\n",
    "    \"irank\": \"int16\"\n",
    "}\n",
    "\n",
    "dtype_item_attr = {\n",
    "    \"item_id\": \"int32\",\n",
    "    \"cate_id\": \"int32\", \n",
    "    \"store_id\": \"int32\"\n",
    "}\n",
    "\n",
    "print(\"📋 数据类型定义完成\")\n",
    "print(\"💾 使用int32/int16减少内存占用\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0708d289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 开始加载数据...\n",
      "✅ 数据加载完成\n",
      "📊 训练数据: 6,989,817 条记录, 483,117 用户\n",
      "📊 测试数据: 140,380 条记录, 10,576 用户\n",
      "📊 商品属性: 1,924,269 条记录\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 数据加载\n",
    "# =============================================================================\n",
    "print(\"📂 开始加载数据...\")\n",
    "\n",
    "# 加载训练数据\n",
    "train = pd.read_csv(TRAIN_CSV, dtype=dtype_train)\n",
    "train['create_order_time'] = pd.to_datetime(train['create_order_time'])\n",
    "\n",
    "# 加载测试数据\n",
    "test = pd.read_csv(TEST_CSV, dtype=dtype_test)\n",
    "test['create_order_time'] = pd.to_datetime(test['create_order_time'])\n",
    "\n",
    "# 加载商品属性数据\n",
    "item_attr = pd.read_csv(ATTR_CSV, dtype=dtype_item_attr)\n",
    "\n",
    "print(\"✅ 数据加载完成\")\n",
    "print(f\"📊 训练数据: {len(train):,} 条记录, {train['buyer_admin_id'].nunique():,} 用户\")\n",
    "print(f\"📊 测试数据: {len(test):,} 条记录, {test['buyer_admin_id'].nunique():,} 用户\")\n",
    "print(f\"📊 商品属性: {len(item_attr):,} 条记录\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e4c28e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T14:56:36.432546Z",
     "iopub.status.busy": "2025-09-15T14:56:36.432445Z",
     "iopub.status.idle": "2025-09-15T14:56:39.956705Z",
     "shell.execute_reply": "2025-09-15T14:56:39.956299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 开始智能分层抽样...\n",
      "📊 原始数据: 6,989,817 条记录, 483,117 用户\n",
      "🎯 开始智能分层抽样: 6,989,817 条记录 -> 目标 10,000 用户\n",
      "  📊 分析用户特征...\n",
      "    📈 用户统计: 483,117 个用户\n",
      "    📊 购买次数范围: 8 - 11766\n",
      "    🛍️ 商品种类范围: 1 - 1086\n",
      "  🎯 定义分层策略...\n",
      "    📊 分层组合数: 75\n",
      "    🎯 目标用户: 10,000\n",
      "    📏 每层配额范围: 100 - 5000\n",
      "    📈 购买次数分位数: 9.0, 11.0, 15.0, 23.0\n",
      "    🛍️ 多样性分位数: 8.0, 10.0, 13.0, 19.0\n",
      "  🎲 执行分层抽样...\n",
      "    ✅ 抽样完成: 10,000 个用户\n",
      "  📊 计算抽样统计...\n",
      "    📈 用户抽样率: 2.1%\n",
      "    📊 记录抽样率: 2.4%\n",
      "    🎯 购买保持度: JSD 0.893 | 统计 0.805\n",
      "    🛍️ 多样保持度: JSD 0.963 | 统计 0.903\n",
      "    ⭐ 综合质量分数: 0.891\n",
      "✅ 抽样完成: 170,699 条记录, 10,000 用户\n",
      "📊 数据保留率: 2.4%\n",
      "  🔍 验证抽样质量...\n",
      "    📋 质量检查结果:\n",
      "      ✅ 用户数量合理\n",
      "      ✅ 记录数量合理\n",
      "      ✅ 购买保持良好(JSD)\n",
      "      ✅ 多样保持良好(JSD)\n",
      "      ✅ 购买统计相似度\n",
      "      ✅ 多样统计相似度\n",
      "      ✅ 综合质量分数\n",
      "    🎉 抽样质量验证通过!\n",
      "✅ 抽样质量验证通过，使用抽样数据\n",
      "📊 最终训练数据: 170,699 条记录, 10,000 用户\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 智能抽样处理\n",
    "# =============================================================================\n",
    "if ENABLE_SAMPLING:\n",
    "    print(f\"\\n🎯 开始智能分层抽样...\")\n",
    "    print(f\"📊 原始数据: {len(train):,} 条记录, {train['buyer_admin_id'].nunique():,} 用户\")\n",
    "    \n",
    "    # 导入智能抽样模块\n",
    "    from smart_sampling import smart_stratified_sampling, validate_sampling_quality\n",
    "    \n",
    "    # 执行智能抽样\n",
    "    train_sampled, sampling_info = smart_stratified_sampling(\n",
    "        train, \n",
    "        target_users=TARGET_USERS, \n",
    "        random_seed=SAMPLING_SEED\n",
    "    )\n",
    "    \n",
    "    # 验证抽样质量\n",
    "    quality_ok = validate_sampling_quality(sampling_info)\n",
    "    \n",
    "    if quality_ok:\n",
    "        print(\"✅ 抽样质量验证通过，使用抽样数据\")\n",
    "        train = train_sampled\n",
    "    else:\n",
    "        print(\"⚠️ 抽样质量不达标，使用全量数据\")\n",
    "    \n",
    "    print(f\"📊 最终训练数据: {len(train):,} 条记录, {train['buyer_admin_id'].nunique():,} 用户\")\n",
    "else:\n",
    "    print(\"🎯 跳过抽样，使用全量数据\")\n",
    "    sampling_info = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f3eae3",
   "metadata": {},
   "source": [
    "## 3️⃣ 数据质量检查\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc9ff690",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T14:56:39.958154Z",
     "iopub.status.busy": "2025-09-15T14:56:39.958044Z",
     "iopub.status.idle": "2025-09-15T14:56:40.183969Z",
     "shell.execute_reply": "2025-09-15T14:56:40.183771Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 开始数据质量检查...\n",
      "✅ 数据字段完整性检查通过\n",
      "\n",
      "📈 数据基础统计:\n",
      "  👥 用户数量: 10,000\n",
      "  🛍️ 商品数量: 93,433\n",
      "  📦 商品属性数量: 1,924,269\n",
      "  📅 时间范围: 2018-03-14 02:44:59 ~ 2018-04-28 23:59:46\n",
      "\n",
      "🔍 缺失值检查:\n",
      "  训练数据缺失值: 0\n",
      "  测试数据缺失值: 0\n",
      "  商品属性缺失值: 0\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 数据完整性检查\n",
    "# =============================================================================\n",
    "print(\"🔍 开始数据质量检查...\")\n",
    "\n",
    "# 定义必需字段\n",
    "REQUIRED_TRAIN_COLS = {'buyer_admin_id', 'item_id', 'create_order_time', 'irank'}\n",
    "REQUIRED_ATTR_COLS = {'item_id', 'cate_id', 'store_id'}\n",
    "\n",
    "# 检查训练数据字段\n",
    "missing_train = REQUIRED_TRAIN_COLS - set(train.columns)\n",
    "missing_test = REQUIRED_TRAIN_COLS - set(test.columns)\n",
    "missing_attr = REQUIRED_ATTR_COLS - set(item_attr.columns)\n",
    "\n",
    "# 断言检查\n",
    "assert len(missing_train) == 0, f'❌ 训练数据缺少字段: {missing_train}'\n",
    "assert len(missing_test) == 0, f'❌ 测试数据缺少字段: {missing_test}'\n",
    "assert len(missing_attr) == 0, f'❌ 商品属性缺少字段: {missing_attr}'\n",
    "\n",
    "print(\"✅ 数据字段完整性检查通过\")\n",
    "\n",
    "# 基础统计信息\n",
    "print(\"\\n📈 数据基础统计:\")\n",
    "print(f\"  👥 用户数量: {train['buyer_admin_id'].nunique():,}\")\n",
    "print(f\"  🛍️ 商品数量: {train['item_id'].nunique():,}\")\n",
    "print(f\"  📦 商品属性数量: {item_attr.shape[0]:,}\")\n",
    "print(f\"  📅 时间范围: {train['create_order_time'].min()} ~ {train['create_order_time'].max()}\")\n",
    "\n",
    "# 检查缺失值\n",
    "print(f\"\\n🔍 缺失值检查:\")\n",
    "print(f\"  训练数据缺失值: {train.isnull().sum().sum()}\")\n",
    "print(f\"  测试数据缺失值: {test.isnull().sum().sum()}\")\n",
    "print(f\"  商品属性缺失值: {item_attr.isnull().sum().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2a079b",
   "metadata": {},
   "source": [
    "## 4️⃣ 数据排序与标准化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "749b958c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T14:56:40.185170Z",
     "iopub.status.busy": "2025-09-15T14:56:40.185098Z",
     "iopub.status.idle": "2025-09-15T14:56:48.412673Z",
     "shell.execute_reply": "2025-09-15T14:56:48.412129Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 正在进行数据排序...\n",
      "✅ 数据排序完成\n",
      "📋 排序字段: buyer_admin_id → create_order_time → irank\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 数据排序标准化\n",
    "# =============================================================================\n",
    "print(\"🔄 正在进行数据排序...\")\n",
    "\n",
    "# 确保数据按时序正确排序\n",
    "# 排序规则: 用户ID -> 时间 -> irank (升序)\n",
    "train = train.sort_values(\n",
    "    ['buyer_admin_id', 'create_order_time', 'irank']\n",
    ").reset_index(drop=True)\n",
    "\n",
    "test = test.sort_values(\n",
    "    ['buyer_admin_id', 'create_order_time', 'irank']\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(\"✅ 数据排序完成\")\n",
    "print(\"📋 排序字段: buyer_admin_id → create_order_time → irank\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f755b71",
   "metadata": {},
   "source": [
    "## 5️⃣ 留一验证切分\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8dff7d60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T14:56:48.415074Z",
     "iopub.status.busy": "2025-09-15T14:56:48.414941Z",
     "iopub.status.idle": "2025-09-15T14:56:48.684439Z",
     "shell.execute_reply": "2025-09-15T14:56:48.684188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 开始留一验证切分...\n",
      "✅ 留一验证切分完成\n",
      "📊 原始训练数据: 170,699 条\n",
      "📊 训练可视数据: 160,699 条\n",
      "📊 标签数据: 10,000 条\n",
      "👥 参与验证的用户: 10,000 人\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 留一验证切分 - 避免数据泄漏\n",
    "# =============================================================================\n",
    "print(\"🔄 开始留一验证切分...\")\n",
    "\n",
    "# 找到每个用户的最后一条购买记录作为标签\n",
    "# 注意: 这里使用idxmin()是因为排序后第一条是最早的记录\n",
    "# 我们需要最后一条记录，所以使用idxmax()\n",
    "last_idx = train.groupby('buyer_admin_id')['irank'].idxmax()\n",
    "\n",
    "# 创建标签数据集\n",
    "label_df = train.loc[last_idx, ['buyer_admin_id', 'item_id']].copy()\n",
    "label_df = label_df.rename(columns={'item_id': 'label_item'})\n",
    "\n",
    "# 创建训练可视数据集（去除标签数据，防止泄漏）\n",
    "train_vis = train.drop(index=last_idx).copy()\n",
    "\n",
    "print(\"✅ 留一验证切分完成\")\n",
    "print(f\"📊 原始训练数据: {train.shape[0]:,} 条\")\n",
    "print(f\"📊 训练可视数据: {train_vis.shape[0]:,} 条\")\n",
    "print(f\"📊 标签数据: {label_df.shape[0]:,} 条\")\n",
    "print(f\"👥 参与验证的用户: {label_df['buyer_admin_id'].nunique():,} 人\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87af2d73",
   "metadata": {},
   "source": [
    "## 6️⃣ 数据保存与输出\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fffbba5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T14:56:48.685587Z",
     "iopub.status.busy": "2025-09-15T14:56:48.685509Z",
     "iopub.status.idle": "2025-09-15T14:56:50.118861Z",
     "shell.execute_reply": "2025-09-15T14:56:50.118628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 正在保存处理后的数据...\n",
      "  ✅ 保存完整训练数据: train_sorted.parquet\n",
      "  ✅ 保存测试数据: test_sorted.parquet\n",
      "  ✅ 保存商品属性数据: item_attr.parquet\n",
      "  ✅ 保存训练可视数据: train_vis.parquet\n",
      "  ✅ 保存标签数据: label_df.parquet\n",
      "  ✅ 保存抽样数据: train_vis_sampled.parquet, label_df_sampled.parquet\n",
      "  ✅ 保存抽样信息: sampling_info.json\n",
      "\n",
      "🎉 数据预处理完成！\n",
      "📁 所有文件已保存到: ../x\n",
      "📊 最终数据规模总结:\n",
      "  - 完整训练数据: (170699, 5)\n",
      "  - 测试数据: (140380, 5)\n",
      "  - 训练可视数据: (160699, 5)\n",
      "  - 标签数据: (10000, 2)\n",
      "  - 商品属性数据: (1924269, 3)\n",
      "\n",
      "📊 抽样统计:\n",
      "  - 用户抽样率: 2.1%\n",
      "  - 记录抽样率: 2.4%\n",
      "  - 购买分布保持度: 0.893\n",
      "  - 多样性保持度: 0.963\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 数据保存 - 生成标准化的中间文件\n",
    "# =============================================================================\n",
    "print(\"💾 正在保存处理后的数据...\")\n",
    "\n",
    "# 保存训练数据（完整版）\n",
    "train.to_parquet(f'{OUTDIR}/train_sorted.parquet', index=False)\n",
    "print(f\"  ✅ 保存完整训练数据: train_sorted.parquet\")\n",
    "\n",
    "# 保存测试数据\n",
    "test.to_parquet(f'{OUTDIR}/test_sorted.parquet', index=False)\n",
    "print(f\"  ✅ 保存测试数据: test_sorted.parquet\")\n",
    "\n",
    "# 保存商品属性数据（去重后）\n",
    "item_attr_clean = item_attr[['item_id', 'cate_id', 'store_id']].drop_duplicates()\n",
    "item_attr_clean.to_parquet(f'{OUTDIR}/item_attr.parquet', index=False)\n",
    "print(f\"  ✅ 保存商品属性数据: item_attr.parquet\")\n",
    "\n",
    "# 保存训练可视数据（用于离线统计）\n",
    "train_vis.to_parquet(f'{OUTDIR}/train_vis.parquet', index=False)\n",
    "print(f\"  ✅ 保存训练可视数据: train_vis.parquet\")\n",
    "\n",
    "# 保存标签数据\n",
    "label_df.to_parquet(f'{OUTDIR}/label_df.parquet', index=False)\n",
    "print(f\"  ✅ 保存标签数据: label_df.parquet\")\n",
    "\n",
    "# 如果启用了抽样，额外保存抽样版本供后续模块使用\n",
    "if ENABLE_SAMPLING and sampling_info is not None:\n",
    "    train_vis.to_parquet(f'{OUTDIR}/train_vis_sampled.parquet', index=False)\n",
    "    label_df.to_parquet(f'{OUTDIR}/label_df_sampled.parquet', index=False)\n",
    "    print(f\"  ✅ 保存抽样数据: train_vis_sampled.parquet, label_df_sampled.parquet\")\n",
    "\n",
    "# 保存抽样信息（如果启用了抽样）\n",
    "if ENABLE_SAMPLING and sampling_info is not None:\n",
    "    sampling_info_path = f'{OUTDIR}/sampling_info.json'\n",
    "    with open(sampling_info_path, 'w', encoding='utf-8') as f:\n",
    "        # 转换numpy类型为Python原生类型\n",
    "        sampling_info_serializable = {}\n",
    "        for k, v in sampling_info.items():\n",
    "            if isinstance(v, np.integer):\n",
    "                sampling_info_serializable[k] = int(v)\n",
    "            elif isinstance(v, np.floating):\n",
    "                sampling_info_serializable[k] = float(v)\n",
    "            else:\n",
    "                sampling_info_serializable[k] = v\n",
    "        \n",
    "        json.dump(sampling_info_serializable, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"  ✅ 保存抽样信息: sampling_info.json\")\n",
    "\n",
    "print(f\"\\n🎉 数据预处理完成！\")\n",
    "print(f\"📁 所有文件已保存到: {OUTDIR}\")\n",
    "print(f\"📊 最终数据规模总结:\")\n",
    "print(f\"  - 完整训练数据: {train.shape}\")\n",
    "print(f\"  - 测试数据: {test.shape}\")\n",
    "print(f\"  - 训练可视数据: {train_vis.shape}\")\n",
    "print(f\"  - 标签数据: {label_df.shape}\")\n",
    "print(f\"  - 商品属性数据: {item_attr_clean.shape}\")\n",
    "\n",
    "if ENABLE_SAMPLING and sampling_info is not None:\n",
    "    print(f\"\\n📊 抽样统计:\")\n",
    "    print(f\"  - 用户抽样率: {sampling_info['user_sampling_ratio']*100:.1f}%\")\n",
    "    print(f\"  - 记录抽样率: {sampling_info['record_sampling_ratio']*100:.1f}%\")\n",
    "    print(f\"  - 购买分布保持度: {sampling_info['purchase_preservation']:.3f}\")\n",
    "    print(f\"  - 多样性保持度: {sampling_info['diversity_preservation']:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
