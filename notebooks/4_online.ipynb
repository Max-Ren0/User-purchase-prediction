{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1f4c559",
   "metadata": {},
   "source": [
    "# 4) 线上推理（提交生成）— Top30\n",
    "\n",
    "- 用 **全量 `train_sorted.parquet`** 重建统计；\n",
    "- 基于 `test_sorted.parquet` 生成候选；\n",
    "- 若找到 **`model_lgb.pkl`**（来自 2_rank），则用它打分；否则退化为 `pre_score`；\n",
    "- 导出提交：`submit_long.csv`（user,item,score,rank）与 `submit_wide.csv`（每行一个用户 30 列）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c430b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, pandas as pd, numpy as np\n",
    "\n",
    "OUTDIR = '/Users/ringscherry/Desktop'  \n",
    "TOPK = 30\n",
    "\n",
    "train = pd.read_parquet(f'{OUTDIR}/train_sorted.parquet')\n",
    "test  = pd.read_parquet(f'{OUTDIR}/test_sorted.parquet')\n",
    "item_attr = pd.read_parquet(f'{OUTDIR}/item_attr.parquet')\n",
    "print('train rows:', len(train), ' test rows:', len(test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eb2b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PARAMS = dict(\n",
    "    covisit_window=3, covisit_top_per_a=200,\n",
    "    recent_k=5, cand_per_recent=40,\n",
    "    tau_days=14,\n",
    "    user_top_cates=3, user_top_stores=3,\n",
    "    per_cate_pool=80, per_store_pool=60,\n",
    "    pop_pool=2000, recall_cap=600,\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3763d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def time_decay(days, tau=14.0):\n",
    "    days = np.maximum(days, 0.0)\n",
    "    return np.exp(-days / float(tau))\n",
    "\n",
    "def build_rebuy_scores(df, tau_days=14):\n",
    "    g = df.copy()\n",
    "    ref = g.groupby('buyer_admin_id')['create_order_time'].transform('max')\n",
    "    g['days_ago'] = (ref - g['create_order_time']).dt.days.clip(lower=0)\n",
    "    g['score_rebuy'] = time_decay(g['days_ago'].to_numpy(), tau=tau_days)\n",
    "    return g.groupby(['buyer_admin_id','item_id'])['score_rebuy'].sum().reset_index()\n",
    "\n",
    "def build_covisit(df, W=3, topk=200):\n",
    "    base = df[['buyer_admin_id','item_id']].copy()\n",
    "    pairs = []\n",
    "    for lag in range(1, W+1):\n",
    "        t = base.copy()\n",
    "        t['item_b'] = t.groupby('buyer_admin_id')['item_id'].shift(-lag)\n",
    "        t = t.dropna().rename(columns={'item_id':'item_a'})\n",
    "        t['w'] = 1.0/lag\n",
    "        pairs.append(t[['item_a','item_b','w']])\n",
    "    if not pairs:\n",
    "        return pd.DataFrame(columns=['item_a','item_b','w'])\n",
    "    co = pd.concat(pairs, ignore_index=True)\n",
    "    co = co.groupby(['item_a','item_b'])['w'].sum().reset_index()\n",
    "    co['rn'] = co.groupby('item_a')['w'].rank(ascending=False, method='first')\n",
    "    return co[co['rn']<=topk].drop(columns='rn')\n",
    "\n",
    "def build_pop_pools(df, item_attr, pop_pool=2000):\n",
    "    pop = df.groupby('item_id').size().rename('pop').reset_index()\n",
    "    cate_pop = (df.merge(item_attr, on='item_id', how='left')\n",
    "                .groupby(['cate_id','item_id']).size().rename('pop').reset_index())\n",
    "    cate_pop['rn'] = cate_pop.groupby('cate_id')['pop'].rank(ascending=False, method='first')\n",
    "    store_pop = (df.merge(item_attr, on='item_id', how='left')\n",
    "                 .groupby(['store_id','item_id']).size().rename('pop').reset_index())\n",
    "    store_pop['rn'] = store_pop.groupby('store_id')['pop'].rank(ascending=False, method='first')\n",
    "    global_pop = pop.sort_values('pop', ascending=False).head(pop_pool)\n",
    "    return cate_pop, store_pop, global_pop\n",
    "\n",
    "rebuy = build_rebuy_scores(train, tau_days=PARAMS['tau_days'])\n",
    "covisit = build_covisit(train, W=PARAMS['covisit_window'], topk=PARAMS['covisit_top_per_a'])\n",
    "cate_pop, store_pop, global_pop = build_pop_pools(train, item_attr, pop_pool=PARAMS['pop_pool'])\n",
    "print('full-train stats built.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f232cb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "P = PARAMS\n",
    "\n",
    "cov_neighbors = {}\n",
    "for a, g in covisit.groupby('item_a'):\n",
    "    sub = g[['item_b','w']].head(P['cand_per_recent']).to_numpy()\n",
    "    if len(sub):\n",
    "        cov_neighbors[int(a)] = (sub[:,0].astype('int64'), sub[:,1].astype('float32'))\n",
    "\n",
    "recent_map = (test.sort_values('create_order_time')\n",
    "              .groupby('buyer_admin_id')['item_id']\n",
    "              .apply(lambda s: s.tail(P['recent_k']).to_numpy('int64'))\n",
    "              ).to_dict()\n",
    "\n",
    "ua = test.merge(item_attr, on='item_id', how='left')\n",
    "user_topc = ua.groupby('buyer_admin_id')['cate_id']               .apply(lambda s: s.value_counts().head(P['user_top_cates']).index.to_numpy('int64')).to_dict()\n",
    "user_tops = ua.groupby('buyer_admin_id')['store_id']               .apply(lambda s: s.value_counts().head(P['user_top_stores']).index.to_numpy('int64')).to_dict()\n",
    "\n",
    "cate_top = {int(c): grp.loc[grp['rn']<=P['per_cate_pool'],'item_id'].to_numpy('int64')\n",
    "            for c, grp in cate_pop.groupby('cate_id')}\n",
    "store_top = {int(s): grp.loc[grp['rn']<=P['per_store_pool'],'item_id'].to_numpy('int64')\n",
    "             for s, grp in store_pop.groupby('store_id')}\n",
    "global_items = global_pop['item_id'].to_numpy('int64')\n",
    "\n",
    "rebuy_map = {}\n",
    "for uid, g in rebuy.groupby('buyer_admin_id'):\n",
    "    rebuy_map[int(uid)] = (g['item_id'].to_numpy('int64'), g['score_rebuy'].to_numpy('float32'))\n",
    "print('precomputed maps ready (online).')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d83251",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_candidates_fast(uid,\n",
    "                          use_rebuy=True, use_covisit=True,\n",
    "                          use_cate_store=True, use_global=True):\n",
    "    cand = {}\n",
    "    if use_rebuy and uid in rebuy_map:\n",
    "        items, ws = rebuy_map[uid]\n",
    "        for it, w in zip(items, ws):\n",
    "            cand.setdefault(int(it), []).append(('rebuy', float(w)))\n",
    "    if use_covisit:\n",
    "        for a in recent_map.get(uid, []):\n",
    "            pair = cov_neighbors.get(int(a))\n",
    "            if pair is None: \n",
    "                continue\n",
    "            bs, ws = pair\n",
    "            for b, w in zip(bs, ws):\n",
    "                cand.setdefault(int(b), []).append(('covisit', float(w)))\n",
    "    if use_cate_store:\n",
    "        for c in user_topc.get(uid, []):\n",
    "            for it in cate_top.get(int(c), ()):\n",
    "                cand.setdefault(int(it), []).append(('cate_hot', 1.0))\n",
    "        for s in user_tops.get(uid, []):\n",
    "            for it in store_top.get(int(s), ()):\n",
    "                cand.setdefault(int(it), []).append(('store_hot', 1.0))\n",
    "    if use_global:\n",
    "        for it in global_items:\n",
    "            cand.setdefault(int(it), []).append(('global_pop', 1.0))\n",
    "\n",
    "    if not cand:\n",
    "        cols = ['buyer_admin_id','item_id','score_rebuy','score_covisit',\n",
    "                'is_cate_hot','is_store_hot','is_global_pop','src_count','pre_score']\n",
    "        return pd.DataFrame(columns=cols)\n",
    "    rows = []\n",
    "    for it, srcs in cand.items():\n",
    "        srcset = set()\n",
    "        sr=sc=0.0; is_c=is_s=is_g=0\n",
    "        for tag, w in srcs:\n",
    "            srcset.add(tag)\n",
    "            if tag=='rebuy': sr=max(sr,w)\n",
    "            elif tag=='covisit': sc=max(sc,w)\n",
    "            elif tag=='cate_hot': is_c=1\n",
    "            elif tag=='store_hot': is_s=1\n",
    "            elif tag=='global_pop': is_g=1\n",
    "        rows.append((int(uid), int(it), sr, sc, is_c, is_s, is_g, len(srcset)))\n",
    "    df = pd.DataFrame(rows, columns=['buyer_admin_id','item_id','score_rebuy','score_covisit',\n",
    "                                     'is_cate_hot','is_store_hot','is_global_pop','src_count'])\n",
    "    df['pre_score'] = (df['score_rebuy'] + df['score_covisit']\n",
    "                       + 0.3*df['is_cate_hot'] + 0.3*df['is_store_hot'] + 0.1*df['is_global_pop'])\n",
    "    return df.sort_values('pre_score', ascending=False).head(PARAMS['recall_cap'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b70a3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 加同分布特征 + 载入模型（若不存在则退化 pre_score） ===\n",
    "try:\n",
    "    import joblib, os\n",
    "    model_path = os.path.join(OUTDIR, 'model_lgb.pkl')\n",
    "    model = joblib.load(model_path) if os.path.exists(model_path) else None\n",
    "    print('Loaded model:', model_path if model is not None else 'None (fallback to pre_score)')\n",
    "except Exception:\n",
    "    model = None\n",
    "    print('joblib not available; fallback to pre_score.')\n",
    "\n",
    "feat_cols = ['score_rebuy','score_covisit','is_cate_hot','is_store_hot','is_global_pop',\n",
    "             'src_count','user_hist_cnt','item_pop_cnt','pre_score']\n",
    "\n",
    "user_cnt_full = train.groupby('buyer_admin_id').size().rename('user_hist_cnt')\n",
    "item_cnt_full = train.groupby('item_id').size().rename('item_pop_cnt')\n",
    "\n",
    "def score_dataframe(cdf):\n",
    "    cdf = (cdf.merge(user_cnt_full, on='buyer_admin_id', how='left')\n",
    "              .merge(item_cnt_full, on='item_id', how='left')).fillna(0)\n",
    "    if (model is not None) and hasattr(model, 'predict_proba'):\n",
    "        cdf['score'] = model.predict_proba(cdf[feat_cols])[:,1]\n",
    "    else:\n",
    "        cdf['score'] = cdf['pre_score']\n",
    "    return cdf[['buyer_admin_id','item_id','score']]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8204242",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 生成 Top30 提交 ===\n",
    "users = test['buyer_admin_id'].unique()\n",
    "rows = []\n",
    "for uid in users:\n",
    "    cdf = build_candidates_fast(int(uid), True, True, True, True)\n",
    "    if len(cdf)==0: \n",
    "        continue\n",
    "    sdf = score_dataframe(cdf).sort_values(['buyer_admin_id','score'], ascending=[True, False]).head(TOPK)\n",
    "    rank = np.arange(1, len(sdf)+1)\n",
    "    sdf = sdf.assign(rank=rank)\n",
    "    rows.append(sdf)\n",
    "\n",
    "submit_long = pd.concat(rows, ignore_index=True) if rows else               pd.DataFrame(columns=['buyer_admin_id','item_id','score','rank'])\n",
    "\n",
    "def to_wide(df, topk=TOPK):\n",
    "    df = df.sort_values(['buyer_admin_id','rank'])\n",
    "    items = df.groupby('buyer_admin_id')['item_id'].apply(list).reset_index()\n",
    "    items['item_list'] = items['item_id'].apply(lambda L: (L + [None]*topk)[:topk])\n",
    "    out = items[['buyer_admin_id','item_list']].copy()\n",
    "    for i in range(topk):\n",
    "        out[f'item_{i+1}'] = out['item_list'].apply(lambda L: L[i])\n",
    "    return out.drop(columns=['item_list'])\n",
    "\n",
    "submit_wide = to_wide(submit_long[['buyer_admin_id','item_id','rank']], TOPK) if len(submit_long) else               pd.DataFrame(columns=['buyer_admin_id'] + [f'item_{i}' for i in range(1, TOPK+1)])\n",
    "\n",
    "submit_long.to_csv(f'{OUTDIR}/submit_long.csv', index=False)\n",
    "submit_wide.to_csv(f'{OUTDIR}/submit_wide.csv', index=False)\n",
    "\n",
    "print('Saved:')\n",
    "print(f'- {OUTDIR}/submit_long.csv')\n",
    "print(f'- {OUTDIR}/submit_wide.csv')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
