# ğŸ¯ è´å¶æ–¯ä¼˜åŒ–å®ç° - æ™ºèƒ½FAST_MODEç‰ˆæœ¬
# åªé™åˆ¶æ•°æ®é‡ï¼Œä¸é™åˆ¶å‚æ•°èŒƒå›´ï¼Œé¿å…æ’é™¤åˆé€‚å‚æ•°

import pandas as pd
import numpy as np
import time
from datetime import datetime
import json
from typing import Dict, Any, Tuple
from skopt import gp_minimize
from skopt.space import Real, Integer
from skopt.utils import use_named_args
from skopt.acquisition import gaussian_ei

class BayesianOptimizer:
    """è´å¶æ–¯ä¼˜åŒ–å™¨ - æ™ºèƒ½FAST_MODEç‰ˆæœ¬"""
    
    def __init__(self, fast_mode: bool = True, user_sample_ratio: float = 0.05):
        self.fast_mode = fast_mode
        self.user_sample_ratio = user_sample_ratio
        self.results = []
        self.best_params = None
        self.best_score = 0
        
        # å‚æ•°æœç´¢èŒƒå›´ï¼ˆåŸºäºåŸå§‹å‚æ•°è®¾ç½®åˆç†èŒƒå›´ï¼‰
        self.param_ranges = {
            'covisit_window': (2, 8),           # åŸå§‹å€¼3ï¼ŒèŒƒå›´2-8
            'covisit_top_per_a': (100, 400),    # åŸå§‹å€¼200ï¼ŒèŒƒå›´100-400
            'recent_k': (3, 15),                # åŸå§‹å€¼5ï¼ŒèŒƒå›´3-15
            'cand_per_recent': (20, 80),        # åŸå§‹å€¼40ï¼ŒèŒƒå›´20-80
            'tau_days': (7, 30),                # åŸå§‹å€¼14ï¼ŒèŒƒå›´7-30
            'user_top_cates': (2, 6),           # åŸå§‹å€¼3ï¼ŒèŒƒå›´2-6
            'user_top_stores': (2, 6),          # åŸå§‹å€¼3ï¼ŒèŒƒå›´2-6
            'per_cate_pool': (40, 150),         # åŸå§‹å€¼80ï¼ŒèŒƒå›´40-150
            'per_store_pool': (30, 120),        # åŸå§‹å€¼60ï¼ŒèŒƒå›´30-120
            'pop_pool': (1000, 4000),           # åŸå§‹å€¼2000ï¼ŒèŒƒå›´1000-4000
            'recall_cap': (300, 1200),          # åŸå§‹å€¼600ï¼ŒèŒƒå›´300-1200
            'batch_size': (1000, 4000),         # åŸå§‹å€¼2000ï¼ŒèŒƒå›´1000-4000
        }
        
        # å®šä¹‰æœç´¢ç©ºé—´
        self.dimensions = [
            Integer(self.param_ranges['covisit_window'][0], 
                   self.param_ranges['covisit_window'][1], name='covisit_window'),
            Integer(self.param_ranges['covisit_top_per_a'][0], 
                   self.param_ranges['covisit_top_per_a'][1], name='covisit_top_per_a'),
            Integer(self.param_ranges['recent_k'][0], 
                   self.param_ranges['recent_k'][1], name='recent_k'),
            Integer(self.param_ranges['cand_per_recent'][0], 
                   self.param_ranges['cand_per_recent'][1], name='cand_per_recent'),
            Integer(self.param_ranges['tau_days'][0], 
                   self.param_ranges['tau_days'][1], name='tau_days'),
            Integer(self.param_ranges['user_top_cates'][0], 
                   self.param_ranges['user_top_cates'][1], name='user_top_cates'),
            Integer(self.param_ranges['user_top_stores'][0], 
                   self.param_ranges['user_top_stores'][1], name='user_top_stores'),
            Integer(self.param_ranges['per_cate_pool'][0], 
                   self.param_ranges['per_cate_pool'][1], name='per_cate_pool'),
            Integer(self.param_ranges['per_store_pool'][0], 
                   self.param_ranges['per_store_pool'][1], name='per_store_pool'),
            Integer(self.param_ranges['pop_pool'][0], 
                   self.param_ranges['pop_pool'][1], name='pop_pool'),
            Integer(self.param_ranges['recall_cap'][0], 
                   self.param_ranges['recall_cap'][1], name='recall_cap'),
            Integer(self.param_ranges['batch_size'][0], 
                   self.param_ranges['batch_size'][1], name='batch_size'),
        ]
    
    def evaluate_params(self, params: Dict[str, Any]) -> Tuple[float, Dict[str, Any]]:
        """
        è¯„ä¼°å‚æ•°ç»„åˆçš„æ•ˆæœ
        
        Args:
            params: å‚æ•°å­—å…¸
        
        Returns:
            score: ç»¼åˆè¯„åˆ†
            metrics: è¯¦ç»†æŒ‡æ ‡
        """
        print(f"ğŸ” æµ‹è¯•å‚æ•°: {params}")
        
        # æ¨¡æ‹Ÿå‚æ•°æ•ˆæœè¯„ä¼°ï¼ˆæ‚¨éœ€è¦æ ¹æ®å®é™…ä¸šåŠ¡æŒ‡æ ‡æ¥å®šä¹‰ï¼‰
        # è¿™é‡Œæä¾›ä¸€ä¸ªç¤ºä¾‹å®ç°
        
        # 1. å¬å›ç‡è¯„åˆ† (40%)
        recall_score = self._estimate_recall_score(params)
        
        # 2. å¤šæ ·æ€§è¯„åˆ† (20%)
        diversity_score = self._estimate_diversity_score(params)
        
        # 3. è®¡ç®—æ•ˆç‡è¯„åˆ† (20%)
        efficiency_score = self._estimate_efficiency_score(params)
        
        # 4. è¦†ç›–ç‡è¯„åˆ† (20%)
        coverage_score = self._estimate_coverage_score(params)
        
        # ç»¼åˆè¯„åˆ†
        total_score = (0.4 * recall_score + 
                      0.2 * diversity_score + 
                      0.2 * efficiency_score + 
                      0.2 * coverage_score)
        
        metrics = {
            'recall_score': recall_score,
            'diversity_score': diversity_score,
            'efficiency_score': efficiency_score,
            'coverage_score': coverage_score,
            'total_score': total_score,
            'fast_mode': self.fast_mode,
            'user_sample_ratio': self.user_sample_ratio
        }
        
        print(f"  ğŸ“Š è¯„åˆ†: {total_score:.3f} (å¬å›:{recall_score:.3f}, å¤šæ ·æ€§:{diversity_score:.3f}, æ•ˆç‡:{efficiency_score:.3f}, è¦†ç›–ç‡:{coverage_score:.3f})")
        
        return total_score, metrics
    
    def _estimate_recall_score(self, params: Dict[str, Any]) -> float:
        """ä¼°ç®—å¬å›ç‡è¯„åˆ†"""
        score = 0
        
        # covisit_window: çª—å£è¶Šå¤§ï¼Œå¬å›è¶Šå¤š
        window_score = min(1.0, params['covisit_window'] / 8.0)
        score += 0.3 * window_score
        
        # recent_k: æœ€è¿‘å•†å“æ•°è¶Šå¤šï¼Œå¬å›è¶Šå¤š
        recent_score = min(1.0, params['recent_k'] / 15.0)
        score += 0.3 * recent_score
        
        # recall_cap: å€™é€‰æ•°è¶Šå¤šï¼Œå¬å›è¶Šå¤š
        cap_score = min(1.0, params['recall_cap'] / 1200.0)
        score += 0.4 * cap_score
        
        return score
    
    def _estimate_diversity_score(self, params: Dict[str, Any]) -> float:
        """ä¼°ç®—å¤šæ ·æ€§è¯„åˆ†"""
        diversity = 0
        
        # å…¨å±€çƒ­é—¨æ± å¤§å°å½±å“å¤šæ ·æ€§
        if params['pop_pool'] > 2000:
            diversity += 0.3
        
        # ç±»ç›®å’Œåº—é“ºæ± å¤§å°å½±å“ä¸ªæ€§åŒ–å¤šæ ·æ€§
        if params['per_cate_pool'] > 80:
            diversity += 0.3
        if params['per_store_pool'] > 60:
            diversity += 0.2
        
        # å…±ç°å…³ç³»æ•°é‡å½±å“ååŒè¿‡æ»¤å¤šæ ·æ€§
        if params['covisit_top_per_a'] > 200:
            diversity += 0.2
        
        return min(1.0, diversity)
    
    def _estimate_efficiency_score(self, params: Dict[str, Any]) -> float:
        """ä¼°ç®—è®¡ç®—æ•ˆç‡è¯„åˆ†"""
        # åŸºäºå‚æ•°å€¼ä¼°ç®—è®¡ç®—å¤æ‚åº¦
        complexity = 0
        
        # å…±ç°è®¡ç®—å¤æ‚åº¦
        covisit_factor = params['covisit_window'] * params['covisit_top_per_a'] / 1000.0
        
        # å€™é€‰ç”Ÿæˆå¤æ‚åº¦
        candidate_factor = params['recent_k'] * params['cand_per_recent'] * params['recall_cap'] / 100000.0
        
        # çƒ­é—¨æ± è®¡ç®—å¤æ‚åº¦
        pool_factor = (params['per_cate_pool'] + params['per_store_pool'] + params['pop_pool']) / 5000.0
        
        total_complexity = covisit_factor + candidate_factor + pool_factor
        
        # æ•ˆç‡è¯„åˆ†ï¼šå¤æ‚åº¦è¶Šä½ï¼Œæ•ˆç‡è¶Šé«˜
        efficiency = max(0, 1.0 - total_complexity / 10.0)
        
        return efficiency
    
    def _estimate_coverage_score(self, params: Dict[str, Any]) -> float:
        """ä¼°ç®—è¦†ç›–ç‡è¯„åˆ†"""
        coverage = 0
        
        # å…¨å±€çƒ­é—¨æ± å½±å“è¦†ç›–ç‡
        if params['pop_pool'] > 2000:
            coverage += 0.4
        
        # ç±»ç›®æ± å½±å“è¦†ç›–ç‡
        if params['per_cate_pool'] > 80:
            coverage += 0.3
        
        # åº—é“ºæ± å½±å“è¦†ç›–ç‡
        if params['per_store_pool'] > 60:
            coverage += 0.3
        
        return min(1.0, coverage)
    
    def run_optimization(self, n_calls: int = 50, random_state: int = 42):
        """
        è¿è¡Œè´å¶æ–¯ä¼˜åŒ–
        
        Args:
            n_calls: è¯„ä¼°æ¬¡æ•°
            random_state: éšæœºç§å­
        
        Returns:
            best_params: æœ€ä½³å‚æ•°
            best_score: æœ€ä½³è¯„åˆ†
        """
        print(f"ğŸ¯ å¼€å§‹è´å¶æ–¯ä¼˜åŒ–")
        print(f"ğŸ“Š æ¨¡å¼: {'å¿«é€Ÿæ¨¡å¼' if self.fast_mode else 'ç”Ÿäº§æ¨¡å¼'}")
        print(f"ğŸ‘¥ ç”¨æˆ·é‡‡æ ·æ¯”ä¾‹: {self.user_sample_ratio*100:.1f}%")
        print(f"ğŸ”„ è¯„ä¼°æ¬¡æ•°: {n_calls}")
        print(f"ğŸ“ å‚æ•°èŒƒå›´: {len(self.param_ranges)} ä¸ªå‚æ•°")
        
        # ç›®æ ‡å‡½æ•°
        @use_named_args(dimensions=self.dimensions)
        def objective(**params):
            score, metrics = self.evaluate_params(params)
            
            # è®°å½•ç»“æœ
            result = {
                'params': params.copy(),
                'score': score,
                'metrics': metrics,
                'timestamp': datetime.now().isoformat()
            }
            self.results.append(result)
            
            # æ›´æ–°æœ€ä½³å‚æ•°
            if score > self.best_score:
                self.best_score = score
                self.best_params = params.copy()
                print(f"  ğŸ‰ æ–°çš„æœ€ä½³å‚æ•°! è¯„åˆ†: {score:.3f}")
            
            return -score  # æœ€å°åŒ–è´Ÿåˆ†æ•°
        
        # è¿è¡Œè´å¶æ–¯ä¼˜åŒ–
        start_time = time.time()
        
        try:
            result = gp_minimize(
                func=objective,
                dimensions=self.dimensions,
                n_calls=n_calls,
                random_state=random_state,
                acq_func='EI'  # ä½¿ç”¨æœŸæœ›æ”¹è¿›é‡‡é›†å‡½æ•°
            )
            
            end_time = time.time()
            
            print(f"\nâœ… è´å¶æ–¯ä¼˜åŒ–å®Œæˆ!")
            print(f"â° æ€»è€—æ—¶: {end_time - start_time:.2f}ç§’")
            print(f"ğŸ† æœ€ä½³è¯„åˆ†: {self.best_score:.3f}")
            print(f"ğŸ¯ æœ€ä½³å‚æ•°: {self.best_params}")
            
            return self.best_params, self.best_score
            
        except Exception as e:
            print(f"âŒ è´å¶æ–¯ä¼˜åŒ–å¤±è´¥: {e}")
            return None, 0
    
    def save_results(self, filename: str = 'bayesian_optimization_results.json'):
        """ä¿å­˜ä¼˜åŒ–ç»“æœ"""
        results_data = {
            'best_params': self.best_params,
            'best_score': self.best_score,
            'all_results': self.results,
            'param_ranges': self.param_ranges,
            'fast_mode': self.fast_mode,
            'user_sample_ratio': self.user_sample_ratio,
            'timestamp': datetime.now().isoformat()
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(results_data, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ ä¼˜åŒ–ç»“æœå·²ä¿å­˜åˆ°: {filename}")
    
    def print_summary(self):
        """æ‰“å°ä¼˜åŒ–æ‘˜è¦"""
        print(f"\nğŸ“Š è´å¶æ–¯ä¼˜åŒ–æ‘˜è¦")
        print(f"=" * 50)
        print(f"ğŸ¯ æ¨¡å¼: {'å¿«é€Ÿæ¨¡å¼' if self.fast_mode else 'ç”Ÿäº§æ¨¡å¼'}")
        print(f"ğŸ‘¥ ç”¨æˆ·é‡‡æ ·æ¯”ä¾‹: {self.user_sample_ratio*100:.1f}%")
        print(f"ğŸ”„ æ€»è¯„ä¼°æ¬¡æ•°: {len(self.results)}")
        print(f"ğŸ† æœ€ä½³è¯„åˆ†: {self.best_score:.3f}")
        print(f"ğŸ¯ æœ€ä½³å‚æ•°:")
        for param, value in self.best_params.items():
            print(f"  {param}: {value}")
        
        # æ˜¾ç¤ºè¯„åˆ†åˆ†å¸ƒ
        if self.results:
            scores = [r['score'] for r in self.results]
            print(f"\nğŸ“ˆ è¯„åˆ†ç»Ÿè®¡:")
            print(f"  æœ€é«˜åˆ†: {max(scores):.3f}")
            print(f"  æœ€ä½åˆ†: {min(scores):.3f}")
            print(f"  å¹³å‡åˆ†: {np.mean(scores):.3f}")
            print(f"  æ ‡å‡†å·®: {np.std(scores):.3f}")

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # å¿«é€Ÿæ¨¡å¼ä¼˜åŒ–
    print("ğŸš€ å¿«é€Ÿæ¨¡å¼è´å¶æ–¯ä¼˜åŒ–")
    fast_optimizer = BayesianOptimizer(fast_mode=True, user_sample_ratio=0.05)
    fast_params, fast_score = fast_optimizer.run_optimization(n_calls=30)
    fast_optimizer.save_results('fast_mode_results.json')
    fast_optimizer.print_summary()
    
    print("\n" + "="*60)
    
    # ç”Ÿäº§æ¨¡å¼ä¼˜åŒ–
    print("ğŸ­ ç”Ÿäº§æ¨¡å¼è´å¶æ–¯ä¼˜åŒ–")
    prod_optimizer = BayesianOptimizer(fast_mode=False, user_sample_ratio=1.0)
    prod_params, prod_score = prod_optimizer.run_optimization(n_calls=50)
    prod_optimizer.save_results('prod_mode_results.json')
    prod_optimizer.print_summary()
